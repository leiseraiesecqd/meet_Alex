{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "import datetime\n",
    "import os,gc\n",
    "import utils\n",
    "import copy\n",
    "\n",
    "file_path='D:/360WiFi/'\n",
    "raw_data_path='D:/360WiFi/FDDC_financial_data_20180613/'\n",
    "split_file_path='D:/360WiFi/files/financial_data_new/'\n",
    "input_path='D:/360WiFi/files/input/'\n",
    "mid_path='D:/360WiFi/files/mid_file/'\n",
    "other_path='D:/360WiFi/files/other_file/'\n",
    "start_time='2009-01-01'\n",
    "\n",
    "'''\n",
    "make_label():添加训练标签（下季度营收额），生成table_6_file_label_new.csv 文件\n",
    "select_table(class_option,del_col):将最终合好的大表进行行列筛选\n",
    "clear_clear():总表生成后，进行行列删除，得到最终总表\n",
    "\n",
    "'''\n",
    "\n",
    "# def drop_rows(T,list_date):\n",
    "#     '''\n",
    "#     去掉公司上市前信息,去掉09年之前的信息\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     print('del some end_date before list_date...')\n",
    "#     early_date=pd.read_csv(other_path+'ticker_market.csv',encoding='gbk')\n",
    "#     early_date_dic=zip(early_date.TICKER_SYMBOL,early_date.listDate)\n",
    "\n",
    "#     #T['END_DATE']=T['END_DATE'].apply(lambda x:datetime.datetime.strftime(x,format='%Y-%m-%d'))\n",
    "#     concat_list=[]\n",
    "#     for (a,b) in early_date_dic:\n",
    "#         concat_list.append(T[(T.TICKER_SYMBOL==a)&(T.END_DATE>=b)])\n",
    "\n",
    "#     T_new=pd.concat(concat_list)\n",
    "#     T_new['END_DATE']=pd.to_datetime(T_new['END_DATE'],format='%Y/%m/%d') \n",
    "#     T_new=T_new[T_new['END_DATE']>=start_time]\n",
    " \n",
    "#     return T_new\n",
    "\n",
    "def select_table(A,class_option,del_col,ticker_option,drop_ticker):\n",
    "    \n",
    "    '''\n",
    "    输入A是要处理为df文件，注意末尾删掉了END_DATE，这之后，进行完分组训和划分训练集之后，还要再删的列：year，month，class_option\n",
    "\n",
    "    ''' \n",
    "\n",
    "    #根据行业分类选择，添加要删除的列名\n",
    "    if class_option=='classifi_by_14L1':\n",
    "        del_col.extend(['classifi_by_14L1'])\n",
    "    elif class_option=='classifi_by_14L2':\n",
    "        del_col.extend(['classifi_by_14L1','classifi_by_14L2'])\n",
    "    elif class_option=='classifi_by_14L3':\n",
    "        del_col.extend(['classifi_by_14L1','classifi_by_14L2','classifi_by_14L3'])\n",
    "        \n",
    "    A.dropna(axis=1,how='all',inplace=True) \n",
    "    \n",
    "    print('drop some ticker \\n')\n",
    "    A=A[~A.TICKER_SYMBOL.isin(drop_ticker)]\n",
    "    print('after drop ticker the shape is',A.shape)\n",
    "    \n",
    "#     Index=A[((A['TICKER_SYMBOL']>=200000)&(A['TICKER_SYMBOL']<300000))|((A['TICKER_SYMBOL']>=900000)&(A['TICKER_SYMBOL']<901000))].index\n",
    "#     A.drop(Index,inplace=True)\n",
    "\n",
    "    #***********************  以2_开头和以900_开头的ticke共计 18个 **********\n",
    "    ##[200053, 200054, 200152, 200160, 200168, 200468, 200512, 200706,\n",
    "    #       200771, 200986, 200992, 900929, 900939, 900948, 900951, 900953,\n",
    "    ##       900956, 900957]\n",
    "\n",
    "    #************************************************************************\n",
    "\n",
    "    \n",
    "   \n",
    "    print('--------------------------------')\n",
    "\n",
    "    ##----去除不要的公司----------------\n",
    "    print('Now drop the special ticker:')\n",
    "    for item in ticker_option:\n",
    "\n",
    "        #print(item) \n",
    "        #print(ticker_option['%s'%item])\n",
    "\n",
    "        if ticker_option[item][2]=='all':\n",
    "\n",
    "            Index=A[(A['TICKER_SYMBOL']==int(item))&(A['END_DATE']>=ticker_option[item][0])&(A['END_DATE']<=ticker_option[item][1])].index\n",
    "            A.drop(Index,inplace=True)\n",
    "            print('successfully del %s record from %s to %s:'%(item,ticker_option[item][0],ticker_option[item][1]))\n",
    "        else:\n",
    "\n",
    "            Index=A[(A['TICKER_SYMBOL']==int(item))&(A['END_DATE']>=ticker_option[item][0])&(A['END_DATE']<=ticker_option[item][1])].index\n",
    "\n",
    "            A.loc[Index,A.columns.str.contains('_%s'%ticker_option[item][2])]=0\n",
    "            print('successfully change %s record as 0 from %s to %s:'%(item,ticker_option[item][0],ticker_option[item][1]))\n",
    " \n",
    "\n",
    "\n",
    "    ##------------去掉上市前公司信息-----------\n",
    "    ###A=drop_rows(A)\n",
    "    \n",
    "#     del A['END_DATE']\n",
    "\n",
    "    print('drop the uesless cols...')\n",
    "    A.drop(del_col,axis=1,inplace=True)\n",
    "    \n",
    "    ##----检查 全为空或者0的列----------------\n",
    "    print('--------------------------------')\n",
    "    print('Now check the [none,0] col:')\n",
    "    check_col=A.sum()\n",
    "    print(check_col[check_col==0].index)\n",
    "\n",
    "    for none_col in check_col[check_col==0].index:\n",
    "        del A[none_col]\n",
    "        print('successfully del:',none_col)\n",
    "    print('--------------------------------')\n",
    "\n",
    "\n",
    "    ##----检查类型异常的列----------------\n",
    "    print('Now check the tpyes of col:')\n",
    "    print(A.get_dtype_counts())\n",
    "    print('--------------------------------')\n",
    "    print('The int col are:')\n",
    "    int_col=A.infer_objects().dtypes\n",
    "    print(int_col[int_col=='int64'])\n",
    "    print('The object col are:')\n",
    "    print(int_col[int_col=='object'])\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def make_label():\n",
    "    '''\n",
    "    计算季度应收并建立下季度营收label，中间生成table_6_file_label文件，最终输出table_6_file_label_new文件\n",
    "    '''\n",
    "\n",
    "    ##---------------------第一阶段：计算营收季度值-----------------------------\n",
    "    table=pd.read_csv(mid_path+'table_6_file.csv')#'REVENUE_commom_income'\n",
    "\n",
    "    ##step1:去掉原表中 营收为空的列，不去为0的\n",
    "\n",
    "    #table['REVENUE_commom_income'].replace(0,np.nan,inplace=True)\n",
    "    table.dropna(subset=['REVENUE_commom_income'],how='any',inplace=True)\n",
    "    sorted(table['REVENUE_commom_income'].values)\n",
    "\n",
    "\n",
    "    ##step2:建立映射关系，month_pre:3-6,6-9,9-12,12-15，merge到原表中。将merge后month=3的填充零。再去掉Nan值。\n",
    "\n",
    "    table['month_pre']=table['month']+3\n",
    "    table['month_pre'].value_counts()\n",
    "    pre_Revenue=table[['TICKER_SYMBOL','year','month_pre','REVENUE_commom_income']]\n",
    "    pre_Revenue.rename(columns={'REVENUE_commom_income':'REVENUE_pre','month_pre':'month'},inplace=True)\n",
    "    table.drop(['month_pre'],axis=1,inplace=True)\n",
    "\n",
    "    merge_1=pd.merge(table,pre_Revenue,how='left',on=['TICKER_SYMBOL','year','month'])\n",
    "\n",
    "    merge_1.loc[merge_1[merge_1.month==3].index,'REVENUE_pre']=0\n",
    "\n",
    "    ##检车NAN值\n",
    "    merge_1[merge_1.REVENUE_pre.isnull()]['month'].value_counts()\n",
    "    #*********************************************\n",
    "    # 6     516\n",
    "    # 12    490\n",
    "    # 9     436\n",
    "    # Name: month, dtype: int64\n",
    "    #************************************************\n",
    "\n",
    "    merge_1.dropna(subset=['REVENUE_pre'],how='any',inplace=True)\n",
    "\n",
    "    #建立label列\n",
    "    merge_1['label']=merge_1.REVENUE_commom_income-merge_1.REVENUE_pre\n",
    "\n",
    "    merge_1.drop(['REVENUE_pre'],axis=1,inplace=True)\n",
    "\n",
    "    merge_1[['TICKER_SYMBOL','year','month','REVENUE_commom_income','label']]\n",
    "    print('当季值营收计算完成',merge_1.shape)\n",
    "\n",
    "    merge_1.to_csv(mid_path+'table_6_file_label.csv',index=False)\n",
    "    \n",
    "    del merge_1,table,pre_Revenue\n",
    "    \n",
    "\n",
    "    ##----------------第二阶段：将季度应收前移--------------------------\n",
    "    \n",
    "    A=pd.read_csv(mid_path+'table_6_file_label.csv')\n",
    "    A[A.TICKER_SYMBOL==1].END_DATE.values\n",
    "\n",
    "    tt=['2009-03-31', '2009-06-30', '2009-09-30', '2009-12-31',\n",
    "           '2010-03-31', '2010-06-30', '2010-09-30', '2010-12-31',\n",
    "           '2011-03-31', '2011-06-30', '2011-09-30', '2011-12-31',\n",
    "           '2012-03-31', '2012-06-30', '2012-09-30', '2012-12-31',\n",
    "           '2013-03-31', '2013-06-30', '2013-09-30', '2013-12-31',\n",
    "           '2014-03-31', '2014-06-30', '2014-09-30', '2014-12-31',\n",
    "           '2015-03-31', '2015-06-30', '2015-09-30', '2015-12-31',\n",
    "           '2016-03-31', '2016-06-30', '2016-09-30', '2016-12-31',\n",
    "           '2017-03-31', '2017-06-30', '2017-09-30', '2017-12-31',\n",
    "           '2018-03-31']\n",
    "\n",
    "\n",
    "    w=[]\n",
    "    ww=[]\n",
    "    for i in range(len(tt)-1):\n",
    "        w.append(tt[i])\n",
    "        ww.append(tt[i+1])\n",
    "    W=DataFrame({'END_DATE':ww,'END_DATE_PRE':w})\n",
    "    AW=pd.merge(A,W,how='left',on=['END_DATE'])\n",
    "    AW=AW[['TICKER_SYMBOL','END_DATE_PRE','label']]\n",
    "    AW.rename(columns={'END_DATE_PRE':'END_DATE'},inplace=True)\n",
    "\n",
    "\n",
    "    B=pd.read_csv(mid_path+'table_6_file.csv')\n",
    "    ABW=pd.merge(B,AW,how='left',on=['TICKER_SYMBOL','END_DATE'])\n",
    "    ABW\n",
    "\n",
    "    ABW_child=ABW[ABW['END_DATE']=='2018-03-31']\n",
    "    #ABW.replace(0,np.nan,inplace=True)\n",
    "    ABW.dropna(subset=['label'],how='any',inplace=True)\n",
    "    ABW_PLUS=pd.concat([ABW,ABW_child])\n",
    "    ABW_PLUS\n",
    "    print('label文件完成',ABW_PLUS.shape)\n",
    "    ABW_PLUS.to_csv(mid_path+'table_6_file_label_new.csv',index=False)\n",
    "\n",
    "\n",
    "    return ABW_PLUS\n",
    "\n",
    "def middle_operation(final,oht_col):\n",
    "    \n",
    "    '''\n",
    "    final是输入的总文件，one_hot_col是one_hot的列\n",
    "    '''\n",
    "    ##进行onehot操作\n",
    "    AA=copy.deepcopy(final)\n",
    "    print('=======================================')\n",
    "    print('onehot encoding...\\n')\n",
    "    print('the origin shape:',AA.shape)\n",
    "    AA=pd.get_dummies(AA,columns=oht_col)\n",
    "    print('after onehot the shape:',AA.shape)\n",
    "\n",
    "\n",
    "    ##添加era列\n",
    "    print('=======================================')\n",
    "    print('adding \"era\" col...')\n",
    "    AA['date']=AA['year'].astype(str)+AA['month'].apply(lambda x:\"%02d\"%x)\n",
    "\n",
    "\n",
    "    tt=['200903', '200906', '200909', '200912', '201003', '201006',\n",
    "           '201009', '201012', '201103', '201106', '201109', '201112',\n",
    "           '201203', '201206', '201209', '201212', '201303', '201306',\n",
    "           '201309', '201312', '201403', '201406', '201409', '201412',\n",
    "           '201503', '201506', '201509', '201512', '201603', '201606',\n",
    "           '201609', '201612', '201703', '201706', '201709', '201712',\n",
    "           '201803','201806']\n",
    "    w=[]\n",
    "    ww=[]\n",
    "    for i in range(len(tt)-1):\n",
    "        w.append(tt[i])\n",
    "        ww.append(tt[i+1])\n",
    "    W=DataFrame({'era':ww,'date':w})\n",
    "    AW=pd.merge(AA,W,how='left',on=['date'])\n",
    "    AW.drop(['date'],axis=1,inplace=True)\n",
    "    print('adding \"era\" finished...')\n",
    "    print('now the shape',AW.shape)\n",
    "\n",
    "    print('=======================================')\n",
    "    ##重新排序\n",
    "    print('reorder the columns\\n')\n",
    "    header=['era','TICKER_SYMBOL','FISCAL_PERIOD_3', 'FISCAL_PERIOD_6', 'FISCAL_PERIOD_9', 'FISCAL_PERIOD_12']\n",
    "    bottom=['REVENUE_pre','REVENUE_now','label','weight']\n",
    "    AW=AW[header+list(AW.columns.drop(header).drop(bottom))+bottom]\n",
    "    print('after reorder,the shape is',AW.shape)\n",
    "    \n",
    "    return AW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
