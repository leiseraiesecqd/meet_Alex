{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "import datetime\n",
    "import os,gc\n",
    "import utils\n",
    "\n",
    "file_path='D:/360WiFi/'\n",
    "raw_data_path='D:/360WiFi/FDDC_financial_data_20180613/'\n",
    "split_file_path='D:/360WiFi/files/financial_data_new/'\n",
    "input_path='D:/360WiFi/files/input/'\n",
    "mid_path='D:/360WiFi/files/mid_file/'\n",
    "other_path='D:/360WiFi/files/other_file/'\n",
    "\n",
    "'''\n",
    "generate_data_base() 执行所有函数，生成table_base 表\n",
    "\n",
    "'''\n",
    "\n",
    "start_time='2009-01-01'\n",
    "\n",
    "\n",
    "def tick_symbol_map():\n",
    "    '''\n",
    "    生成ticker_symbol_2006/2008文件\n",
    "    '''\n",
    "    \n",
    "    h=pd.read_csv(other_path+'level_1_3_industry_class_shenwan.csv',encoding='gbk')\n",
    "    h=h[['ticker','industryID','industrySymbol','intoDate','outDate','isNew']]\n",
    "    h['outDate']=h['outDate'].fillna('2018/3/30')\n",
    "\n",
    "    h['intoDate']=pd.to_datetime(h['intoDate'],format='%Y/%m/%d') \n",
    "    h['outDate']=pd.to_datetime(h['outDate'],format='%Y/%m/%d') \n",
    "    h=h[h['outDate']>='2006-01-01']\n",
    "    h=h.sort_values(by=['ticker','intoDate'])\n",
    "    h['intoDate']=h['intoDate'].apply(lambda x:datetime.datetime.strftime(x,format='%Y/%m/%d') )\n",
    "    h['outDate']=h['outDate'].apply(lambda x:datetime.datetime.strftime(x,format='%Y/%m/%d') )\n",
    "    h\n",
    "    month_list=[]\n",
    "    ticker_list=[]\n",
    "    symbol_list=[]\n",
    "    id_list=[]\n",
    "    for indexs in h.index:\n",
    "        month=getBetweenMonth(h.loc[indexs,'intoDate'],h.loc[indexs,'outDate'])\n",
    "        month_list.extend(month)\n",
    "        ticker=h.loc[indexs,'ticker']\n",
    "        ticker_list.extend([ticker for x in range(len(month))])\n",
    "        symbol=h.loc[indexs,'industrySymbol']\n",
    "        symbol_list.extend([symbol for x in range(len(month))])\n",
    "        id_=h.loc[indexs,'industryID']\n",
    "        id_list.extend([id_ for x in range(len(month))])\n",
    "\n",
    "    print(len(month_list))\n",
    "    print(len(ticker_list))\n",
    "    print(len(symbol_list))\n",
    "    print(len(id_list))\n",
    "    id_symbol=DataFrame({'TICKER_SYMBOL':ticker_list,'time':month_list,'industrySymbol_level_3':symbol_list,'industryID':id_list})\n",
    "    id_symbol.drop_duplicates(['TICKER_SYMBOL','time'], keep='last',inplace=True)\n",
    "    return id_symbol\n",
    "\n",
    "\n",
    "def merge_base():\n",
    "    '''\n",
    "    基于Market Data和ticker_symbol_2006，生成merge_base基准表，\n",
    "    \n",
    "    '''\n",
    "    #market_data=pd.read_csv(file_path+'/files/Market Data_20180529.csv',encoding='gbk')\n",
    "    market_data=pd.read_excel(other_path+'[New] Market Data_20180613.xlsx',encoding='gbk')\n",
    "    ticker_symbol=pd.read_csv(other_path6+'ticker_symbol_2006.csv',encoding='gbk')\n",
    "    market_data['END_DATE_']=pd.to_datetime(market_data['END_DATE_'],format='%Y/%m/%d') \n",
    "    market_data=market_data[['TICKER_SYMBOL','END_DATE_','TYPE_ID']]\n",
    "    market_data.rename(columns={'TYPE_ID':'industryID_level_3'},inplace=True)\n",
    "\n",
    "\n",
    "    market_data['year']=market_data['END_DATE_'].dt.year\n",
    "    market_data['month']=market_data['END_DATE_'].dt.month\n",
    "\n",
    "    market_data=market_data[market_data['END_DATE_']>='2008-01-01']\n",
    "    ticker_symbol['year']=ticker_symbol['time'].map(lambda x:'%s'%str(x)[0:4]).astype(int)\n",
    "    ticker_symbol['month']=ticker_symbol['time'].map(lambda x:'%s'%str(x)[4:]).astype(int)\n",
    "    ticker_symbol=ticker_symbol[ticker_symbol['TICKER_SYMBOL']!='DY600018']\n",
    "    ticker_symbol['TICKER_SYMBOL']=ticker_symbol['TICKER_SYMBOL'].astype(int)\n",
    "\n",
    "    ticker_symbol\n",
    "    test=pd.merge(ticker_symbol,market_data,how='left',on=['TICKER_SYMBOL','year','month'])\n",
    "    \n",
    "    ##以market data中symbol为准，如果有不同，则将industryID替换为market data中的id\n",
    "    index_=test[(test['industryID']!=test['industryID_level_3'])&(test['industryID_level_3'].isnull().values==False)].index#找出两列不相等值的地方\n",
    "    #test[(test['industryID_level_3'].isnull().values==False)]#选出某列不为空的记录\n",
    "    test.loc[index_,'industryID']=test.loc[index_,'industryID_level_3']\n",
    "\n",
    "    test.to_csv(file_path+'merge_base.csv',index=False)\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "##生成 Bigtable表\n",
    "def gengerate_big_table():\n",
    "    '''\n",
    "    merge_base：包含公司从上市以来每个月对应的industry_ID,\n",
    "    ID_industry_index_Symbol:industry_ID对应的一二三级industry_symbol\n",
    "    \n",
    "    以上两者merge后，生成ticker_industry_record.csv,\n",
    "    \n",
    "    再和mergefile（大表）merge生成Bigtable\n",
    "    '''\n",
    "\n",
    "    base=pd.read_csv(mid_path+'merge_base.csv',encoding='gbk')\n",
    "    base.drop(['industrySymbol_level_3','time','END_DATE_','industryID_level_3'],axis=1,inplace=True)\n",
    "    base.rename(columns={'industryID':'industryID_level_3'},inplace=True)\n",
    "\n",
    "\n",
    "    id_symbol=pd.read_csv(other_path+'ID_industry_index_Symbol.csv',encoding='gbk')\n",
    "    columns=['industrySymbol_level_1', 'industrySymbol_level_2', 'industrySymbol_level_3', 'indexSymbol_level_1',\\\n",
    "            'indexSymbol_level_2','indexSymbol_level_3']\n",
    "    for item in columns:\n",
    "        id_symbol[item]=id_symbol[item].fillna(0).astype(int)\n",
    "\n",
    "    tick_symbol_index=pd.merge(base,id_symbol,on=['industryID_level_3'])\n",
    "    \n",
    "    tick_symbol_index.to_csv(other_path+'ticker_industry_record.csv',index=False,encoding='gbk')\n",
    "    ###tick_symbol_index[tick_symbol_index['TICKER_SYMBOL']==600832].sort_values(by=['year','month'])\n",
    "\n",
    "    Table=pd.read_csv(mid_path+'merge_file.csv',encoding='gbk')\n",
    "\n",
    "    Table['END_DATE']=pd.to_datetime(Table['END_DATE'],format='%Y/%m/%d') \n",
    "\n",
    "    Table['year']=Table['END_DATE'].dt.year\n",
    "    Table['month']=Table['END_DATE'].dt.month\n",
    "\n",
    "\n",
    "    Bigtable=pd.merge(Table,tick_symbol_index,how='left',on=['TICKER_SYMBOL','year','month'])\n",
    "    Bigtable.drop(['year', 'month','level_1','level_2'],axis=1,inplace=True)#删除tick_symbol_index中一些无用特征\n",
    "\n",
    "\n",
    "    Bigtable[['industryID_level_3', 'industryID_level_1', 'industryName_level_1',\n",
    "           'industrySymbol_level_1', 'indexSymbol_level_1', 'industryID_level_2',\n",
    "           'industryName_level_2', 'industrySymbol_level_2', 'indexSymbol_level_2',\n",
    "           'industryName_level_3', 'industrySymbol_level_3', 'indexSymbol_level_3',\n",
    "           'isNew']]\n",
    "\n",
    "    columns=['industrySymbol_level_1','indexSymbol_level_1','industrySymbol_level_2',\\\n",
    "             'indexSymbol_level_2','industrySymbol_level_3', 'indexSymbol_level_3']\n",
    "    for item in columns:\n",
    "        Bigtable[item]=Bigtable[item].fillna(0).astype(int)\n",
    "    \n",
    "    return Bigtable\n",
    "\n",
    "\n",
    "class Table_base(object):\n",
    "    \n",
    "    '''\n",
    "    在Bigtable基础上，添加class_by_14L1,2,3三列\n",
    "    '''\n",
    "    def __init__(self,table):\n",
    "        self.Bigtable=table\n",
    "        pass\n",
    "        \n",
    "    '''\n",
    "    财报信息早于股市信息，所以有一些在财报发布年份，公司的具体行业代码尚不清楚。其中一部分可以根据level1_3完善(ticker_symbol)去解决，正在想办法。还有一部分暂时解决不了。\n",
    "    '''\n",
    "    #@staticmethod \n",
    "    def L1_classifi(self):\n",
    "        '''\n",
    "        一级分类操作\n",
    "        '''\n",
    "        print('adding 1st level classify columns ')\n",
    "        Bigtable=self.Bigtable\n",
    "        Bigtable['Mid_L2']=Bigtable['industrySymbol_level_2']\n",
    "        Bigtable['Mid_L3']=Bigtable['industrySymbol_level_3']\n",
    "        Bigtable['classifi_by_14L1']=Bigtable['industrySymbol_level_1']\n",
    "\n",
    "        index_1=Bigtable[(Bigtable['Mid_L2']==340200)|(Bigtable['Mid_L2']==340100)].index\n",
    "        index_1\n",
    "        Bigtable.loc[index_1,'Mid_L2']=Bigtable.loc[index_1,'Mid_L2'].map({340200:340400,340100:340400})\n",
    "        class_map_L1=pd.read_csv(file_path+'/files/value_map/classifi_by_14L1.csv')\n",
    "        class_map_L1\n",
    "        dic_14L1=dict(zip(class_map_L1.indusSymbol_L23_11,class_map_L1.indusSymbol_L1_14))\n",
    "        dic_14L1\n",
    "        for (a,b) in dic_14L1.items():\n",
    "            index_2=Bigtable[(Bigtable['Mid_L2']==a)|(Bigtable['Mid_L3']==a)].index\n",
    "            Bigtable.loc[index_2,'classifi_by_14L1']=b\n",
    "\n",
    "        Bigtable[(Bigtable['Mid_L2']==250100)|(Bigtable['Mid_L3']==310307)]\n",
    "        Bigtable.classifi_by_14L1.unique()\n",
    "        Bigtable[Bigtable['classifi_by_14L1']==0]\n",
    "        \n",
    "        return Bigtable\n",
    "\n",
    "    #@staticmethod \n",
    "    def map_08_11(self):\n",
    "        '''\n",
    "        实现08-11年的代码转换\n",
    "        '''\n",
    "        \n",
    "        Bigtable=self.Bigtable\n",
    "        #08-11一般替换\n",
    "        map_0811_basic=pd.read_csv(file_path+'/files/value_map/map_08_11_basic.csv',encoding='gbk')\n",
    "        map_0811_basic_dic=dict(zip(map_0811_basic['08_L3_symbol'],zip(map_0811_basic['11_L3_symbol'],map_0811_basic['11_L2_symbol'])))\n",
    "        map_0811_basic_dic.items()\n",
    "        for (a,(b,c)) in map_0811_basic_dic.items():\n",
    "            index_2=Bigtable[Bigtable['Mid_L3']==a].index\n",
    "            Bigtable.loc[index_2,'Mid_L3']=b\n",
    "            Bigtable.loc[index_2,'Mid_L2']=c\n",
    "\n",
    "        #08-11特殊替换\n",
    "        map_0811_specific=pd.read_csv(file_path+'/files/value_map/map_08_11_specific.csv',encoding='gbk')\n",
    "        map_0811_specific['ticker']=map_0811_specific['ticker'].fillna(0).astype(int)\n",
    "        map_0811_specific\n",
    "        map_0811_specific_dic=dict(zip(map_0811_specific['ticker'],zip(map_0811_specific['08_L3_symbol'],\\\n",
    "                                    zip(map_0811_specific['11_L3_symbol'],map_0811_specific['11_L2_symbol']))))\n",
    "        for (a,(b,(c,d))) in map_0811_specific_dic.items():\n",
    "            #sample:2263 220501 220501 220500\n",
    "            #print(a,b,c,d)\n",
    "            index_2=Bigtable[(Bigtable['END_DATE']<'2011-10-10')&(Bigtable['TICKER_SYMBOL']==a)&(Bigtable['Mid_L3']==b)].index\n",
    "            Bigtable.loc[index_2,'Mid_L3']=c\n",
    "            Bigtable.loc[index_2,'Mid_L2']=d\n",
    "\n",
    "        return Bigtable\n",
    "\n",
    "    #@staticmethod \n",
    "    def L2_classifi(self):\n",
    "        '''\n",
    "        二级分类操作\n",
    "        '''\n",
    "        print('adding 2nd level classify columns ')\n",
    "        Bigtable=self.L1_classifi()\n",
    "        Bigtable['Mid_L2']=Bigtable['industrySymbol_level_2']\n",
    "        Bigtable['Mid_L3']=Bigtable['industrySymbol_level_3']\n",
    "        Bigtable['classifi_by_14L2']=Bigtable['industrySymbol_level_2']\n",
    "\n",
    "        Bigtable=self.map_08_11()\n",
    "\n",
    "        #一般转换11-14\n",
    "        class_map_L2_basic=pd.read_csv(file_path+'/files/value_map/classifi_by_14L2_basic.csv',encoding='gbk')\n",
    "        class_map_L2_basic\n",
    "        dic_14L2_basic=dict(zip(class_map_L2_basic.indusSymbol_L3_11,class_map_L2_basic.indusSymbol_L2_14))\n",
    "        dic_14L2_basic.items()\n",
    "        for (a,b) in dic_14L2_basic.items():\n",
    "            index_2=Bigtable[(Bigtable['END_DATE']<='2014-01-01')&(Bigtable['Mid_L3']==a)].index\n",
    "            Bigtable.loc[index_2,'classifi_by_14L2']=b\n",
    "\n",
    "\n",
    "        #特殊转换11-14\n",
    "        class_map_L2_specific=pd.read_csv(file_path+'/files/value_map/classifi_by_14L2_specific.csv',encoding='gbk')\n",
    "        class_map_L2_specific\n",
    "        dic_14L2_specific=dict(zip(class_map_L2_specific.ticker,zip(class_map_L2_specific.indusSymbol_L3_11,class_map_L2_specific.indusSymbol_L2_14)))\n",
    "        dic_14L2_specific.items()\n",
    "        for (a,(b,c)) in dic_14L2_specific.items():\n",
    "            #sample:2081 250202 620200\n",
    "            #print(a,b,c)\n",
    "            index_2=Bigtable[(Bigtable['END_DATE']<='2014-01-01')&(Bigtable['TICKER_SYMBOL']==a)&(Bigtable['Mid_L3']==b)].index\n",
    "            Bigtable.loc[index_2,'classifi_by_14L2']=c\n",
    "        return Bigtable\n",
    "\n",
    "    #@staticmethod \n",
    "    def L3_classifi(self):\n",
    "\n",
    "        ##三级分类操作\n",
    "        print('adding 3rd level classify columns ')\n",
    "        Bigtable=self.L2_classifi()\n",
    "        Bigtable['Mid_L2']=Bigtable['industrySymbol_level_2']\n",
    "        Bigtable['Mid_L3']=Bigtable['industrySymbol_level_3']\n",
    "        Bigtable['classifi_by_14L3']=Bigtable['industrySymbol_level_3']\n",
    "\n",
    "        Bigtable=self.map_08_11()\n",
    "\n",
    "        #一般转换11-14\n",
    "        class_map_L3_basic=pd.read_csv(file_path+'/files/value_map/classifi_by_14L3_basic.csv',encoding='gbk')\n",
    "        class_map_L3_basic\n",
    "        dic_14L3_basic=dict(zip(class_map_L3_basic.indusSymbol_L3_11,class_map_L3_basic.indusSymbol_L3_14))\n",
    "        dic_14L3_basic.items()\n",
    "        for (a,b) in dic_14L3_basic.items():\n",
    "            #print(a,b)\n",
    "            index_2=Bigtable[(Bigtable['END_DATE']<='2014-01-01')&(Bigtable['Mid_L3']==a)].index\n",
    "            Bigtable.loc[index_2,'classifi_by_14L3']=b\n",
    "\n",
    "\n",
    "        #特殊转换11-14\n",
    "        class_map_L3_specific=pd.read_csv(file_path+'/files/value_map/classifi_by_14L3_specific.csv',encoding='gbk')\n",
    "        #先处理一下空格\n",
    "        class_map_L3_specific['ticker']=class_map_L3_specific['ticker'].apply(lambda x: 0 if x.isspace() else x)\n",
    "        class_map_L3_specific['ticker']=class_map_L3_specific['ticker'].astype(int)\n",
    "\n",
    "        dic_14L3_specific=zip(class_map_L3_specific.indusSymbol_L3_11,zip(class_map_L3_specific.ticker,class_map_L3_specific.indusSymbol_L3_14))\n",
    "        dic_14L3_specific\n",
    "\n",
    "        for (a,(b,c)) in dic_14L3_specific:\n",
    "            #sample:260404 2350 630402\n",
    "            #print(a,b,c)\n",
    "            index_2=Bigtable[(Bigtable['END_DATE']<='2014-01-01')&(Bigtable['TICKER_SYMBOL']==b)&(Bigtable['Mid_L3']==a)].index\n",
    "            Bigtable.loc[index_2,'classifi_by_14L3']=c\n",
    " \n",
    "\n",
    "        return  Bigtable\n",
    "\n",
    "\n",
    "\n",
    "def drop_rows(T):\n",
    "    print('del some end_date before list_date...')\n",
    "    early_date=pd.read_csv(other_path+'ticker_market.csv',encoding='gbk')\n",
    "    early_date_dic=zip(early_date.TICKER_SYMBOL,early_date.listDate)\n",
    "\n",
    "    T['END_DATE']=T['END_DATE'].apply(lambda x:datetime.datetime.strftime(x,format='%Y-%m-%d'))\n",
    "    concat_list=[]\n",
    "    for (a,b) in early_date_dic:\n",
    "        concat_list.append(T[(T.TICKER_SYMBOL==a)&(T.END_DATE>=b)])\n",
    "\n",
    "    T_new=pd.concat(concat_list)\n",
    "    T_new['END_DATE']=pd.to_datetime(T_new['END_DATE'],format='%Y/%m/%d') \n",
    "    T_new=T_new[T_new['END_DATE']>=start_time]\n",
    "    \n",
    "    return T_new\n",
    "\n",
    "def generate_data_base():\n",
    "    table=gengerate_big_table()\n",
    "    T=Table_base(table).L3_classifi()\n",
    "    TT=drop_rows(T)\n",
    "    TT.to_csv(mid_path+'table_base.csv',index=False)\n",
    "    return TT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
