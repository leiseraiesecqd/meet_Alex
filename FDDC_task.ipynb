{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ipynb_importer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import utils,preprocess,merge_base\n",
    "import time\n",
    "import datetime\n",
    "import os,gc\n",
    "file_path='D:/360WiFi/'\n",
    "raw_data_path='D:/360WiFi/FDDC_financial_data_20180613/'\n",
    "split_file_path='D:/360WiFi/files/financial_data_new/'\n",
    "input_path='D:/360WiFi/files/input/'\n",
    "mid_path='D:/360WiFi/files/mid_file/'\n",
    "other_path='D:/360WiFi/files/other_file/'\n",
    "\n",
    "\n",
    "#资产负债表\n",
    "del_col_Balance_Bank=['AE,AA,LE,LA,SEE,SEA,OTH_EFFECT_SE,OTH_EFFECT_SA,LEE,LEA']\n",
    "del_col_Balance_GB=['CAE,CAA,NCAE,NCAA,AE,AA,CLE,CLA,NCLE,NCLA,LE,LA,SEE,SEA,OTH_EFFECT_SE,OTH_EFFECT_SA,LEE,LEA']\n",
    "del_col_Balance_Insurance=['AE,AA,LE,LA,SEE,SEA,OTH_EFFECT_SE,OTH_EFFECT_SA,LEE,LEA']\n",
    "del_col_Balance_Securities=['AE,AA,LE,LA,SEE,SEA,OTH_EFFECT_SE,OTH_EFFECT_SA,LEE,LEA']\n",
    "\n",
    "#现金流量表\n",
    "del_col_cashFlow_Bank=['SPEC_OCIF,AOCIF,SPEC_OCOF,AOCOF,ANOCF,SPEC_ICIF,AICIF,SPEC_ICOF,AICOF,ANICF,SPEC_FCIF,AFCIF,SPEC_FCOF,AFCOF,ANFCF,OTH_EFFECT_CE,ACE,OTH_EFFECT_CEI,ACEI']\n",
    "del_col_cashFlow_GB=['SPEC_OCIF,AOCIF,SPEC_OCOF,AOCOF,ANOCF,SPEC_ICIF,AICIF,SPEC_ICOF,AICOF,ANICF,SPEC_FCIF,AFCIF,SPEC_FCOF,AFCOF,ANFCF,OTH_EFFECT_CE,ACE,OTH_EFFECT_CEI,ACEI']\n",
    "del_col_cashFlow_Insurance=['SPEC_OCIF,AOCIF,SPEC_OCOF,AOCOF,ANOCF,SPEC_ICIF,AICIF,SPEC_ICOF,AICOF,ANICF,SPEC_FCIF,AFCIF,SPEC_FCOF,AFCOF,ANFCF,OTH_EFFECT_CE,ACE,OTH_EFFECT_CEI,ACEI']\n",
    "del_col_cashFlow_Securities=['SPEC_OCIF,AOCIF,SPEC_OCOF,AOCOF,ANOCF,SPEC_ICIF,AICIF,SPEC_ICOF,AICOF,ANICF,SPEC_FCIF,AFCIF,SPEC_FCOF,AFCOF,ANFCF,OTH_EFFECT_CE,ACE,OTH_EFFECT_CEI,ACEI']\n",
    "\n",
    "\n",
    "#利润表\n",
    "del_col_Income_Bank=['SPEC_OR,AOR,SPEC_OC,AOC,OTH_EFFECT_OP,AE_EFFECT_OP,OTH_EFFECT_TP,AE_EFFECT_TP,OTH_EFFECT_NP,AE_EFFECT_NP,OTH_EFFECT_NPP,AE_EFFECT_NPP,OTH_EFFECT_CI,AE_EFFECT_CI,OTH_EFFECT_PCI,AE_EFFECT_PCI']\n",
    "del_col_Income_GB=['SPEC_TOR,ATOR,SPEC_TOC,ATOC,OTH_EFFECT_OP,AE_EFFECT_OP,OTH_EFFECT_TP,AE_EFFECT_TP,OTH_EFFECT_NP,AE_EFFECT_NP,OTH_EFFECT_NPP,AE_EFFECT_NPP,OTH_EFFECT_CI,AE_EFFECT_CI,OTH_EFFECT_PCI,AE_EFFECT_PCI']\n",
    "del_col_Income_Insurance=['SPEC_OR,AOR,SPEC_OC,AOC,OTH_EFFECT_OP,AE_EFFECT_OP,OTH_EFFECT_TP,AE_EFFECT_TP,OTH_EFFECT_NP,AE_EFFECT_NP,OTH_EFFECT_NPP,AE_EFFECT_NPP,OTH_EFFECT_CI,AE_EFFECT_CI,OTH_EFFECT_PCI,AE_EFFECT_PCI']\n",
    "del_col_Income_Securities=['SPEC_OR,AOR,SPEC_OC,AOC,OTH_EFFECT_OP,AE_EFFECT_OP,OTH_EFFECT_TP,AE_EFFECT_TP,OTH_EFFECT_NP,AE_EFFECT_NP,OTH_EFFECT_NPP,AE_EFFECT_NPP,OTH_EFFECT_CI,AE_EFFECT_CI,OTH_EFFECT_PCI,AE_EFFECT_PCI']\n",
    "\n",
    "\n",
    "\n",
    "del_list=[del_col_Balance_Bank,del_col_Balance_GB,del_col_Balance_Insurance,del_col_Balance_Securities,\\\n",
    "         del_col_cashFlow_Bank,del_col_cashFlow_GB,del_col_cashFlow_Insurance,del_col_cashFlow_Securities,\\\n",
    "        del_col_Income_Bank,del_col_Income_GB,del_col_Income_Insurance,del_col_Income_Securities]\n",
    "\n",
    "#preprocess.preprocess(del_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##探究主表的列类型\n",
    "\n",
    "A=pd.read_csv(mid_path+'table_6_file.csv')\n",
    "#A.columns[A.columns.str.contains('REVE')]#列中包含某字符的列名\n",
    "#A.get_dtype_counts() 列的类型计数\n",
    "\n",
    "#A.infer_objects().dtypes#具体到每列的类型\n",
    "#t#[t=='object']\n",
    "\n",
    "\n",
    "'''\n",
    "注意这之后，先把全为空列删除，进行完分组训和划分训练集之后，还要再删的列：year，month，class_chocie\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class_chocie='classifi_by_14L1'\n",
    "\n",
    "oht_col=['TICKER_SYMBOL','FISCAL_PERIOD','industrySymbol_level_1','industrySymbol_level_2','industrySymbol_level_1',\\\n",
    "        'indexSymbol_level_1','indexSymbol_level_2','indexSymbol_level_3',\\\n",
    "        ]\n",
    "\n",
    "del_col=['PARTY_ID','EXCHANGE_CD', 'PUBLISH_DATE','END_DATE_REP',\\\n",
    "         'END_DATE', 'REPORT_TYPE','MERGED_FLAG', 'category',\\\n",
    "        'industryName_level_1','industryName_level_2','industryName_level_3','isNew','Mid_L2','Mid_L3',\\\n",
    "         'industryID_level_1','industryID_level_2','industryID_level_3',\\\n",
    "         'PUBLISH_DATE_y','PUBLISH_DATE_x','END_DATE_REP_x','END_DATE_REP_y'\n",
    "        ]\n",
    "\n",
    "def select_table(A,class_chocie,del_col):\n",
    "\n",
    "    class_col=['classifi_by_14L1','classifi_by_14L2','classifi_by_14L3']\n",
    "    class_col.remove(class_chocie)\n",
    "\n",
    "    del_col.extend(class_col)\n",
    "    del_col\n",
    "    \n",
    "    A.dropna(axis=1,how='all',inplace=True) \n",
    "    A.drop(del_col,axis=1,inplace=True)\n",
    "\n",
    "    ##----检查 全为空或者0的列----------------\n",
    "    print('--------------------------------')\n",
    "    print('Now eheck the [none,0] col:\\n')\n",
    "    check_col=A.sum()\n",
    "    print(check_col[check_col==0].index)\n",
    "    print('\\n')\n",
    "\n",
    "    for none_col in check_col[check_col==0].index:\n",
    "        del A[none_col]\n",
    "        print('successfully del:',none_col)\n",
    "    print('--------------------------------')\n",
    "\n",
    "\n",
    "    ##----检查类型异常的列----------------\n",
    "    print('Now check the tpyes of col:\\n')\n",
    "    print(A.get_dtype_counts())\n",
    "    print('--------------------------------')\n",
    "    print('The int col are:\\n')\n",
    "    int_col=A.infer_objects().dtypes\n",
    "    print(int_col[int_col=='int64'])\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    return \n",
    "select_table(A,class_chocie,del_col)\n",
    "#A.infer_objects().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_new.industrySymbol_level_1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare(df1,df2):\n",
    "#     '''\n",
    "#     比较表间ticker异同\n",
    "    \n",
    "#     '''\n",
    "#     print(len(df1.TICKER_SYMBOL.unique()))\n",
    "#     print(len(df2.TICKER_SYMBOL.unique()))\n",
    "#     print(set(df1.TICKER_SYMBOL.unique())-set(df2.TICKER_SYMBOL.unique()))\n",
    "#     print(set(df2.TICKER_SYMBOL.unique())-set(df1.TICKER_SYMBOL.unique()))\n",
    "    \n",
    "    \n",
    "# compare(balance_sheet_Securities_old,income_sheet_Securities_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###-------生成器读取文件-----------------\n",
    "# def loading_inputs():\n",
    "#     files= os.listdir(input_path+'/raw_data/')\n",
    "#     for file in files:\n",
    "#         print('reading file:%s'%file)\n",
    "#         feature = pd.read_csv(input_path+'/raw_data/'+file)\n",
    "#         yield feature\n",
    "# T=[]\n",
    "# for item in loading_inputs():\n",
    "#     T.append(item)\n",
    "\n",
    "\n",
    "###-------读取文件---------------------\n",
    "def loading_inputs():\n",
    "    files= os.listdir(input_path+'/raw_data/')\n",
    "    DF=[]\n",
    "    for file in files:\n",
    "        print('reading file:%s'%file)\n",
    "        feature = pd.read_csv(input_path+'/raw_data/'+file)\n",
    "        DF.append(feature)\n",
    "    \n",
    "    return DF\n",
    "\n",
    "\n",
    "def preprocess_common(del_list):\n",
    "    '''\n",
    "    输入是要删除的列，输出是删除指定列并去重的df\n",
    "    \n",
    "    '''\n",
    "    print('----------------------------------------------------')\n",
    "    print('Starting preprocessing....\\n')\n",
    "    print('=======================================================')\n",
    "    print('loading file...')\n",
    "    T=loading_inputs()\n",
    "\n",
    "    ##--------预处理:删列操作-------------------\n",
    "    print('=======================================================')\n",
    "    print('del some cols...')\n",
    "    for i in range(12):\n",
    "        print('del col of df')\n",
    "        try:\n",
    "            T[i]=T[i].drop(del_list[i][0].split(','),axis=1)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "\n",
    "    ##-----------单表去重操作----------------------------\n",
    "\n",
    "    print('single sheet drop_duplicates...')\n",
    "\n",
    "    for i in range(12):\n",
    "        T[i]=utils.date_time_index(T[i]).drop_duplicates(subset=['TICKER_SYMBOL','END_DATE'], keep='last')\n",
    "\n",
    "    return T\n",
    "\n",
    "def preprocess_normal(T):\n",
    "    '''\n",
    "    处理正常的ticker,首先对三大表内部各自合四表，最后合三大表\n",
    "    \n",
    "    '''\n",
    "    print('=======================================================')\n",
    "    print('preprosessing the normal ticker...')\n",
    "    [balance_sheet_Bank_old,balance_sheet_GB_old,balance_sheet_Insurance_old,balance_sheet_Securities_old,\\\n",
    "    cashFlow_sheet_Bank_old,cashFlow_sheet_GB_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_Securities_old,\\\n",
    "    income_sheet_Bank_old,income_sheet_GB_old,income_sheet_Insurance_old,income_sheet_Securities_old]=T\n",
    "    del T\n",
    "    gc.collect()\n",
    "\n",
    "    ###----------------预处理：添加类别列，找公共columns-----------------------\n",
    "    ##添加类别列\n",
    "\n",
    "    balance_sheet_Bank_old['category']='Bank'\n",
    "    cashFlow_sheet_Bank_old['category']='Bank'\n",
    "    income_sheet_Bank_old['category']='Bank'\n",
    "\n",
    "    balance_sheet_Securities_old['category']='Securities'\n",
    "    cashFlow_sheet_Securities_old['category']='Securities'\n",
    "    income_sheet_Securities_old['category']='Securities'\n",
    "\n",
    "    balance_sheet_Insurance_old['category']='Insurance'\n",
    "    cashFlow_sheet_Insurance_old['category']='Insurance'\n",
    "    income_sheet_Insurance_old['category']='Insurance'\n",
    "\n",
    "    balance_sheet_GB_old['category']='GB'\n",
    "    cashFlow_sheet_GB_old['category']='GB'\n",
    "    income_sheet_GB_old['category']='GB'\n",
    "\n",
    "\n",
    "    ##查找columns公共部分\n",
    "        #资产负债\n",
    "    A1=balance_sheet_Bank_old.columns\n",
    "    B1=balance_sheet_Securities_old.columns\n",
    "    C1=balance_sheet_Insurance_old.columns\n",
    "    D1=balance_sheet_GB_old.columns\n",
    "        #现金流量\n",
    "    A2=cashFlow_sheet_Bank_old.columns\n",
    "    B2=cashFlow_sheet_Securities_old.columns\n",
    "    C2=cashFlow_sheet_Insurance_old.columns\n",
    "    D2=cashFlow_sheet_GB_old.columns\n",
    "        #利润表\n",
    "    A3=income_sheet_Bank_old.columns\n",
    "    B3=income_sheet_Securities_old.columns\n",
    "    C3=income_sheet_Insurance_old.columns\n",
    "    D3=income_sheet_GB_old.columns\n",
    "\n",
    "\n",
    "    #确定最终放在表首的几列\n",
    "    common=['INDEX','END_DATE', 'END_DATE_REP','EXCHANGE_CD','FISCAL_PERIOD','MERGED_FLAG','PARTY_ID',\\\n",
    "     'PUBLISH_DATE','REPORT_TYPE','TICKER_SYMBOL','category']\n",
    "\n",
    "\n",
    "\n",
    "    ##分别对三表，找出每个表中四个类别公共部分\n",
    "\n",
    "    commom_balance=set(C1)&set(D1)&set(A1)&set(B1)#-set(common)\n",
    "    commom_cash=set(C2)&set(D2)&set(A2)&set(B2)#-set(common)\n",
    "    commom_income=set(C3)&set(D3)&set(A3)&set(B3)#-set(common)\n",
    "\n",
    "    commom_balance=list(commom_balance)\n",
    "    commom_cash=list(commom_cash)\n",
    "    commom_income=list(commom_income)\n",
    "\n",
    "    ##列出几个特殊ticker,暂时去掉\n",
    "\n",
    "    del_ticker=[563, 627, 712, 750, 776, 987, 2673, 600291, 600816]\n",
    "\n",
    "    T1=[balance_sheet_Bank_old,balance_sheet_GB_old,balance_sheet_Insurance_old,balance_sheet_Securities_old,\\\n",
    "     cashFlow_sheet_Bank_old,cashFlow_sheet_GB_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_Securities_old,\\\n",
    "    income_sheet_Bank_old,income_sheet_GB_old,income_sheet_Insurance_old,income_sheet_Securities_old]\n",
    "\n",
    "    for i in range(12):\n",
    "        #选出不在列表中出现的ticker的数据\n",
    "        IN=np.logical_not(T1[i].TICKER_SYMBOL.isin(del_ticker))\n",
    "        T1[i]=T1[i][IN]\n",
    "\n",
    "    [balance_sheet_Bank_old,balance_sheet_GB_old,balance_sheet_Insurance_old,balance_sheet_Securities_old,\\\n",
    "     cashFlow_sheet_Bank_old,cashFlow_sheet_GB_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_Securities_old,\\\n",
    "    income_sheet_Bank_old,income_sheet_GB_old,income_sheet_Insurance_old,income_sheet_Securities_old]=T1\n",
    "    del T1\n",
    "    gc.collect()    \n",
    "\n",
    "\n",
    "    ##--------------------资产负债表合表------------------------------\n",
    "\n",
    "    print('merging Balance sheet.....\\n')\n",
    "\n",
    "    #提取公共部分并concat\n",
    "\n",
    "    concat_list_balance=[balance_sheet_Bank_old[commom_balance],balance_sheet_Securities_old[commom_balance],\\\n",
    "            balance_sheet_Insurance_old[commom_balance],balance_sheet_GB_old[commom_balance]]\n",
    "\n",
    "    df_balance_common=pd.concat(concat_list_balance)\n",
    "\n",
    "    #将公共部分统一加后缀\n",
    "    old_common_column_balance=list(set(commom_balance)-set(common))\n",
    "    new_common_column_balance=[x+'_commom_balance' for x in old_common_column_balance]\n",
    "\n",
    "    df_balance_common.rename(columns=dict(zip(old_common_column_balance,new_common_column_balance)),inplace=True)\n",
    "    df_balance_common\n",
    "\n",
    "\n",
    "    ##依次提取并merge四表剩余部分\n",
    "\n",
    "    balance_df=[balance_sheet_Bank_old,balance_sheet_Securities_old,balance_sheet_Insurance_old,balance_sheet_GB_old]\n",
    "    name=['_balance_Bank','_balance_Securities','_balance_Insurance','_balance_GB']\n",
    "    balance_list=[]\n",
    "\n",
    "    for a,b in zip(balance_df,name):    \n",
    "        balance_bank_columns=list(set(a.columns)-set(commom_balance))\n",
    "        balance_bank_columns.extend(common)\n",
    "        t=set(balance_bank_columns)-set(common)\n",
    "        balance_bank_columns_new=[x+ b for x in t]\n",
    "        balance_sheet_Bank_old_rest=a[balance_bank_columns]\n",
    "        balance_sheet_Bank_old_rest.rename(columns=dict(zip(t,balance_bank_columns_new)),inplace=True)\n",
    "\n",
    "        balance_list.append(balance_sheet_Bank_old_rest)\n",
    "    '''\n",
    "     merge有一个大bug,左连接时，merge(a,b),如果a和b都有中有多行相同，如a中有 ee行 = ff行  ，而b中也有  cc行= dd 行  ，\n",
    "     且 ee=cc=ff=dd就会出现最终merge结果条数>a；或者说b中有两条与a中某条对应，亦是如此.\n",
    "  \n",
    "    '''   \n",
    "\n",
    "    merge1=pd.merge(df_balance_common,balance_list[0],how='left',on=common)\n",
    "    merge2=pd.merge(merge1,balance_list[1],how='left',on=common)\n",
    "    merge3=pd.merge(merge2,balance_list[2],how='left',on=common)\n",
    "    merge_balance=pd.merge(merge3,balance_list[3],how='left',on=common)\n",
    "\n",
    "    merge_balance\n",
    "\n",
    "    ##--------------------现金流量表合表------------------------------\n",
    "    print('merging CashFlow sheet.....\\n')\n",
    "\n",
    "    #提取公共部分并concat\n",
    "\n",
    "    concat_list_cashFlow=[cashFlow_sheet_Bank_old[commom_cash],cashFlow_sheet_Securities_old[commom_cash],\\\n",
    "    cashFlow_sheet_Insurance_old[commom_cash],cashFlow_sheet_GB_old[commom_cash]]\n",
    "    df_cashFlow_common=pd.concat(concat_list_cashFlow)\n",
    "\n",
    "    df_cashFlow_common\n",
    "\n",
    "    #将公共部分统一加后缀\n",
    "    old_common_column_cash=list(set(commom_cash)-set(common))\n",
    "    new_common_column_cash=[x+'_commom_cash' for x in old_common_column_cash]\n",
    "    df_cashFlow_common.rename(columns=dict(zip(old_common_column_cash,new_common_column_cash)),inplace=True)\n",
    "\n",
    "    df_cashFlow_common\n",
    "\n",
    "\n",
    "    ##依次提取并merge四表剩余部分\n",
    "\n",
    "    cash_df=[cashFlow_sheet_Bank_old,cashFlow_sheet_Securities_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_GB_old]\n",
    "    name=['_cashFlow_Bank','_cashFlow_Securities','_cashFlow_Insurance','_cashFlow_GB']\n",
    "    cash_list=[]\n",
    "\n",
    "    for a,b in zip(cash_df,name):    \n",
    "        cash_bank_columns=list(set(a.columns)-set(commom_cash))\n",
    "        cash_bank_columns.extend(common)\n",
    "        t=set(cash_bank_columns)-set(common)\n",
    "        cash_bank_columns_new=[x+ b for x in t]\n",
    "        cash_sheet_Bank_old_rest=a[cash_bank_columns]\n",
    "        cash_sheet_Bank_old_rest.rename(columns=dict(zip(t,cash_bank_columns_new)),inplace=True)\n",
    "\n",
    "        cash_list.append(cash_sheet_Bank_old_rest)\n",
    "\n",
    "\n",
    "    merge1=pd.merge(df_cashFlow_common,cash_list[0],how='left',on=common)\n",
    "    merge2=pd.merge(merge1,cash_list[1],how='left',on=common)\n",
    "    merge3=pd.merge(merge2,cash_list[2],how='left',on=common)\n",
    "    merge_cash=pd.merge(merge3,cash_list[3],how='left',on=common)\n",
    "    merge_cash\n",
    "\n",
    "    ##--------------------利润表合表------------------------------\n",
    "    print('merging Income sheet.....\\n')\n",
    "\n",
    "    #提取公共部分并concat\n",
    "\n",
    "    concat_list_income=[income_sheet_Bank_old[commom_income],income_sheet_Securities_old[commom_income],\\\n",
    "    income_sheet_Insurance_old[commom_income],income_sheet_GB_old[commom_income]]\n",
    "    df_income_common=pd.concat(concat_list_income)\n",
    "\n",
    "    df_income_common\n",
    "\n",
    "    #将公共部分统一加后缀\n",
    "    old_common_column_income=list(set(commom_income)-set(common))\n",
    "    new_common_column_income=[x+'_commom_income' for x in old_common_column_income]\n",
    "    df_income_common.rename(columns=dict(zip(old_common_column_income,new_common_column_income)),inplace=True)\n",
    "\n",
    "    df_income_common\n",
    "\n",
    "\n",
    "    ##依次提取并merge四表剩余部分\n",
    "\n",
    "    income_df=[income_sheet_Bank_old,income_sheet_Securities_old,income_sheet_Insurance_old,income_sheet_GB_old]\n",
    "    name=['_income_Bank','_income_Securities','_income_Insurance','_income_GB']\n",
    "    income_list=[]\n",
    "\n",
    "    for a,b in zip(income_df,name):    \n",
    "        income_bank_columns=list(set(a.columns)-set(commom_income))\n",
    "        income_bank_columns.extend(common)\n",
    "        t=set(income_bank_columns)-set(common)\n",
    "        income_bank_columns_new=[x+ b for x in t]\n",
    "        income_sheet_Bank_old_rest=a[income_bank_columns]\n",
    "        income_sheet_Bank_old_rest.rename(columns=dict(zip(t,income_bank_columns_new)),inplace=True)\n",
    "\n",
    "        income_list.append(income_sheet_Bank_old_rest)\n",
    "\n",
    "    merge1=pd.merge(df_income_common,income_list[0],how='left',on=common)\n",
    "    merge2=pd.merge(merge1,income_list[1],how='left',on=common)\n",
    "    merge3=pd.merge(merge2,income_list[2],how='left',on=common)\n",
    "    merge_income=pd.merge(merge3,income_list[3],how='left',on=common)\n",
    "    merge_income\n",
    "\n",
    "\n",
    "    ##----------------合三表-------------------------\n",
    "\n",
    "    print('merging final sheet.....\\n')\n",
    "    merge_balance=merge_balance.drop(['INDEX'],axis=1)\n",
    "    merge_cash=merge_cash.drop(['INDEX'],axis=1)\n",
    "    merge_income=merge_income.drop(['INDEX'],axis=1)\n",
    "    merge_income\n",
    "\n",
    "    M1=pd.merge(merge_balance,merge_cash,how='outer',on=['END_DATE','EXCHANGE_CD','FISCAL_PERIOD','MERGED_FLAG','PARTY_ID',\\\n",
    "                                         'REPORT_TYPE','TICKER_SYMBOL','category'])##index,publist_date h和 enddate_rep应该删掉！\n",
    "    M2=pd.merge(M1,merge_income,how='outer',on=['END_DATE','EXCHANGE_CD','FISCAL_PERIOD','MERGED_FLAG','PARTY_ID',\\\n",
    "                                         'REPORT_TYPE','TICKER_SYMBOL','category'])\n",
    "    \n",
    "    \n",
    "    print('preprosessing the normal ticker done!!!...\\n')\n",
    "    print('=======================================================')\n",
    "    return M2\n",
    "\n",
    "def preprocess_special(T):\n",
    "    \n",
    "    '''\n",
    "    处理有冲突的ticker,首先对三大表内部各自合四表，最后合三大表\n",
    "    \n",
    "    '''\n",
    "    print('preprosessing the special ticker...')\n",
    "    [balance_sheet_Bank_old,balance_sheet_GB_old,balance_sheet_Insurance_old,balance_sheet_Securities_old,\\\n",
    "     cashFlow_sheet_Bank_old,cashFlow_sheet_GB_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_Securities_old,\\\n",
    "    income_sheet_Bank_old,income_sheet_GB_old,income_sheet_Insurance_old,income_sheet_Securities_old]=T\n",
    "    del T\n",
    "    gc.collect()\n",
    "\n",
    "    ###----------------预处理：添加类别列，找公共columns-----------------------\n",
    "    ##添加类别列\n",
    "\n",
    "    balance_sheet_Bank_old['category']='SSR'\n",
    "    cashFlow_sheet_Bank_old['category']='SSR'\n",
    "    income_sheet_Bank_old['category']='SSR'\n",
    "\n",
    "    balance_sheet_Securities_old['category']='SSR'\n",
    "    cashFlow_sheet_Securities_old['category']='SSR'\n",
    "    income_sheet_Securities_old['category']='SSR'\n",
    "\n",
    "    balance_sheet_Insurance_old['category']='SSR'\n",
    "    cashFlow_sheet_Insurance_old['category']='SSR'\n",
    "    income_sheet_Insurance_old['category']='SSR'\n",
    "\n",
    "    balance_sheet_GB_old['category']='SSR'\n",
    "    cashFlow_sheet_GB_old['category']='SSR'\n",
    "    income_sheet_GB_old['category']='SSR'\n",
    "\n",
    "\n",
    "\n",
    "    ##查找columns公共部分\n",
    "        #资产负债\n",
    "    A1=balance_sheet_Bank_old.columns\n",
    "    B1=balance_sheet_Securities_old.columns\n",
    "    C1=balance_sheet_Insurance_old.columns\n",
    "    D1=balance_sheet_GB_old.columns\n",
    "        #现金流量\n",
    "    A2=cashFlow_sheet_Bank_old.columns\n",
    "    B2=cashFlow_sheet_Securities_old.columns\n",
    "    C2=cashFlow_sheet_Insurance_old.columns\n",
    "    D2=cashFlow_sheet_GB_old.columns\n",
    "        #利润表\n",
    "    A3=income_sheet_Bank_old.columns\n",
    "    B3=income_sheet_Securities_old.columns\n",
    "    C3=income_sheet_Insurance_old.columns\n",
    "    D3=income_sheet_GB_old.columns\n",
    "\n",
    "\n",
    "    #确定最终放在表首的几列\n",
    "    common=['INDEX','END_DATE', 'END_DATE_REP','EXCHANGE_CD','FISCAL_PERIOD','MERGED_FLAG','PARTY_ID',\\\n",
    "     'PUBLISH_DATE','REPORT_TYPE','TICKER_SYMBOL','category']\n",
    "\n",
    "\n",
    "    ##分别对三表，找出每个表中四个类别公共部分\n",
    "\n",
    "    commom_balance=set(C1)&set(D1)&set(A1)&set(B1)#-set(common)\n",
    "    commom_cash=set(C2)&set(D2)&set(A2)&set(B2)#-set(common)\n",
    "    commom_income=set(C3)&set(D3)&set(A3)&set(B3)#-set(common)\n",
    "\n",
    "    commom_balance=list(commom_balance)\n",
    "    commom_cash=list(commom_cash)\n",
    "    commom_income=list(commom_income)\n",
    "\n",
    "\n",
    "\n",
    "    ##选出ticker条目\n",
    "    del_ticker=[563, 627, 712, 750, 776, 987, 2673, 600291, 600816]\n",
    "\n",
    "    T1=[balance_sheet_Bank_old,balance_sheet_GB_old,balance_sheet_Insurance_old,balance_sheet_Securities_old,\\\n",
    "     cashFlow_sheet_Bank_old,cashFlow_sheet_GB_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_Securities_old,\\\n",
    "    income_sheet_Bank_old,income_sheet_GB_old,income_sheet_Insurance_old,income_sheet_Securities_old]\n",
    "\n",
    "    for i in range(12):\n",
    "        T1[i]=T1[i][T1[i].TICKER_SYMBOL.isin(del_ticker)]\n",
    "\n",
    "    [balance_sheet_Bank_old,balance_sheet_GB_old,balance_sheet_Insurance_old,balance_sheet_Securities_old,\\\n",
    "     cashFlow_sheet_Bank_old,cashFlow_sheet_GB_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_Securities_old,\\\n",
    "    income_sheet_Bank_old,income_sheet_GB_old,income_sheet_Insurance_old,income_sheet_Securities_old]=T1\n",
    "\n",
    "    del T1\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    ##--------------------资产负债表合表------------------------------\n",
    "\n",
    "    print('merging Balance sheet.....\\n')\n",
    "\n",
    "\n",
    "    #提取公共部分并concat\n",
    "\n",
    "\n",
    "    concat_list_balance=[balance_sheet_Bank_old[commom_balance],balance_sheet_Securities_old[commom_balance],\\\n",
    "            balance_sheet_Insurance_old[commom_balance],balance_sheet_GB_old[commom_balance]]\n",
    "\n",
    "    df_balance_common=pd.concat(concat_list_balance)\n",
    "\n",
    "    #将公共部分统一加后缀\n",
    "    old_common_column_balance=list(set(commom_balance)-set(common))\n",
    "    new_common_column_balance=[x+'_commom_balance' for x in old_common_column_balance]\n",
    "\n",
    "    df_balance_common.rename(columns=dict(zip(old_common_column_balance,new_common_column_balance)),inplace=True)\n",
    "    df_balance_common\n",
    "\n",
    "\n",
    "\n",
    "    ##依次提取并merge四表剩余部分\n",
    "\n",
    "    balance_df=[balance_sheet_Bank_old,balance_sheet_Securities_old,balance_sheet_Insurance_old,balance_sheet_GB_old]\n",
    "    name=['_balance_Bank','_balance_Securities','_balance_Insurance','_balance_GB']\n",
    "    balance_list=[]\n",
    "\n",
    "    for a,b in zip(balance_df,name):    \n",
    "        balance_bank_columns=list(set(a.columns)-set(commom_balance))\n",
    "        balance_bank_columns.extend(common)\n",
    "        t=set(balance_bank_columns)-set(common)\n",
    "        balance_bank_columns_new=[x+ b for x in t]\n",
    "        balance_sheet_Bank_old_rest=a[balance_bank_columns]\n",
    "        balance_sheet_Bank_old_rest.rename(columns=dict(zip(t,balance_bank_columns_new)),inplace=True)\n",
    "\n",
    "        balance_list.append(balance_sheet_Bank_old_rest)\n",
    "\n",
    "    ##再次去重    \n",
    "    df_balance_common=df_balance_common.sort_values(by=['TICKER_SYMBOL','END_DATE','PUBLISH_DATE','END_DATE_REP'])\n",
    "    df_balance_common.drop_duplicates(subset=['TICKER_SYMBOL','END_DATE'],keep='last',inplace=True)                                                    \n",
    "\n",
    "\n",
    "    merge1=pd.merge(df_balance_common,balance_list[0],how='left',on=common)\n",
    "    merge2=pd.merge(merge1,balance_list[1],how='left',on=common)\n",
    "    merge3=pd.merge(merge2,balance_list[2],how='left',on=common)\n",
    "    merge_balance=pd.merge(merge3,balance_list[3],how='left',on=common)\n",
    "\n",
    "    merge_balance\n",
    "\n",
    "\n",
    "#     ##-------------检查concat后是否重复-------------------------\n",
    "\n",
    "#     t=df_balance_common.groupby(['TICKER_SYMBOL','END_DATE']).size()\n",
    "#     t=t[t!=1].reset_index()#.to_csv(file_path+'Balance_conflict.csv',index=False)\n",
    "\n",
    "\n",
    "#     def check_ssr(df):\n",
    "#     '''\n",
    "#     找出concat后，重复ticker-enddate，的条目数据，公共部分columns是否一致\n",
    "#     '''\n",
    "#         t=df.groupby(['TICKER_SYMBOL','END_DATE']).size()\n",
    "#         t=t[t!=1].reset_index()\n",
    "#         t.END_DATE=t.END_DATE.apply(lambda x:datetime.datetime.strftime(x,'%Y-%m-%d'))\n",
    "#         for m,n in zip(t.TICKER_SYMBOL,t.END_DATE):\n",
    "#             a=list(df.columns)\n",
    "#             a.remove('PUBLISH_DATE')\n",
    "#             a.remove('END_DATE_REP')\n",
    "#             a.remove('INDEX')\n",
    "#             if len(df[(df.TICKER_SYMBOL==m)&(df.END_DATE==n)].drop_duplicates(subset=a))==1:\n",
    "#                 print(m,n)#to_csv(file_path+'123.csv',index=False)#.drop_duplicates(subset=a)\n",
    "\n",
    "\n",
    "\n",
    "    ##--------------------现金流量表合表------------------------------\n",
    "    print('merging CashFlow sheet.....\\n')\n",
    "\n",
    "    #提取公共部分并concat\n",
    "\n",
    "    concat_list_cashFlow=[cashFlow_sheet_Bank_old[commom_cash],cashFlow_sheet_Securities_old[commom_cash],\\\n",
    "    cashFlow_sheet_Insurance_old[commom_cash],cashFlow_sheet_GB_old[commom_cash]]\n",
    "    df_cashFlow_common=pd.concat(concat_list_cashFlow)\n",
    "\n",
    "    df_cashFlow_common\n",
    "\n",
    "    #将公共部分统一加后缀\n",
    "    old_common_column_cash=list(set(commom_cash)-set(common))\n",
    "    new_common_column_cash=[x+'_commom_cash' for x in old_common_column_cash]\n",
    "    df_cashFlow_common.rename(columns=dict(zip(old_common_column_cash,new_common_column_cash)),inplace=True)\n",
    "\n",
    "    df_cashFlow_common\n",
    "\n",
    "\n",
    "\n",
    "    ##依次提取并merge四表剩余部分\n",
    "\n",
    "    cash_df=[cashFlow_sheet_Bank_old,cashFlow_sheet_Securities_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_GB_old]\n",
    "    name=['_cashFlow_Bank','_cashFlow_Securities','_cashFlow_Insurance','_cashFlow_GB']\n",
    "    cash_list=[]\n",
    "\n",
    "    for a,b in zip(cash_df,name):    \n",
    "        cash_bank_columns=list(set(a.columns)-set(commom_cash))\n",
    "        cash_bank_columns.extend(common)\n",
    "        t=set(cash_bank_columns)-set(common)\n",
    "        cash_bank_columns_new=[x+ b for x in t]\n",
    "        cash_sheet_Bank_old_rest=a[cash_bank_columns]\n",
    "        cash_sheet_Bank_old_rest.rename(columns=dict(zip(t,cash_bank_columns_new)),inplace=True)\n",
    "\n",
    "        cash_list.append(cash_sheet_Bank_old_rest)\n",
    "\n",
    "    ##再次去重\n",
    "    df_cashFlow_common=df_cashFlow_common.sort_values(by=['TICKER_SYMBOL','END_DATE','PUBLISH_DATE','END_DATE_REP'])\n",
    "    df_cashFlow_common.drop_duplicates(subset=['TICKER_SYMBOL','END_DATE'],keep='last',inplace=True)       \n",
    "\n",
    "    merge1=pd.merge(df_cashFlow_common,cash_list[0],how='left',on=common)\n",
    "    merge2=pd.merge(merge1,cash_list[1],how='left',on=common)\n",
    "    merge3=pd.merge(merge2,cash_list[2],how='left',on=common)\n",
    "    merge_cash=pd.merge(merge3,cash_list[3],how='left',on=common)\n",
    "    merge_cash\n",
    "\n",
    "\n",
    "    ##--------------------利润表合表------------------------------\n",
    "    print('merging Income sheet.....\\n')\n",
    "\n",
    "    #提取公共部分并concat\n",
    "\n",
    "    concat_list_income=[income_sheet_Bank_old[commom_income],income_sheet_Securities_old[commom_income],\\\n",
    "    income_sheet_Insurance_old[commom_income],income_sheet_GB_old[commom_income]]\n",
    "    df_income_common=pd.concat(concat_list_income)\n",
    "\n",
    "    df_income_common\n",
    "\n",
    "    #将公共部分统一加后缀\n",
    "    old_common_column_income=list(set(commom_income)-set(common))\n",
    "    new_common_column_income=[x+'_commom_income' for x in old_common_column_income]\n",
    "    df_income_common.rename(columns=dict(zip(old_common_column_income,new_common_column_income)),inplace=True)\n",
    "\n",
    "    df_income_common\n",
    "\n",
    "\n",
    "    ##依次提取并merge四表剩余部分\n",
    "\n",
    "    income_df=[income_sheet_Bank_old,income_sheet_Securities_old,income_sheet_Insurance_old,income_sheet_GB_old]\n",
    "    name=['_income_Bank','_income_Securities','_income_Insurance','_income_GB']\n",
    "    income_list=[]\n",
    "\n",
    "    for a,b in zip(income_df,name):    \n",
    "        income_bank_columns=list(set(a.columns)-set(commom_income))\n",
    "        income_bank_columns.extend(common)\n",
    "        t=set(income_bank_columns)-set(common)\n",
    "        income_bank_columns_new=[x+ b for x in t]\n",
    "        income_sheet_Bank_old_rest=a[income_bank_columns]\n",
    "        income_sheet_Bank_old_rest.rename(columns=dict(zip(t,income_bank_columns_new)),inplace=True)\n",
    "\n",
    "        income_list.append(income_sheet_Bank_old_rest)\n",
    "\n",
    "\n",
    "    ##再次去重\n",
    "    df_income_common=df_income_common.sort_values(by=['TICKER_SYMBOL','END_DATE','PUBLISH_DATE','END_DATE_REP'])\n",
    "    df_income_common.drop_duplicates(subset=['TICKER_SYMBOL','END_DATE'],keep='last',inplace=True) \n",
    "\n",
    "\n",
    "    merge1=pd.merge(df_income_common,income_list[0],how='left',on=common)\n",
    "    merge2=pd.merge(merge1,income_list[1],how='left',on=common)\n",
    "    merge3=pd.merge(merge2,income_list[2],how='left',on=common)\n",
    "    merge_income=pd.merge(merge3,income_list[3],how='left',on=common)\n",
    "    merge_income\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##----------------合三表-------------------------\n",
    "\n",
    "    print('merging final sheet.....\\n')\n",
    "    merge_balance=merge_balance.drop(['INDEX'],axis=1)\n",
    "    merge_cash=merge_cash.drop(['INDEX'],axis=1)\n",
    "    merge_income=merge_income.drop(['INDEX'],axis=1)\n",
    "    merge_income\n",
    "\n",
    "    M1=pd.merge(merge_balance,merge_cash,how='outer',on=['END_DATE','EXCHANGE_CD','FISCAL_PERIOD','MERGED_FLAG','PARTY_ID',\\\n",
    "                                         'REPORT_TYPE','TICKER_SYMBOL','category'])\n",
    "    M2=pd.merge(M1,merge_income,how='outer',on=['END_DATE','EXCHANGE_CD','FISCAL_PERIOD','MERGED_FLAG','PARTY_ID',\\\n",
    "                                         'REPORT_TYPE','TICKER_SYMBOL','category'])\n",
    "    M2\n",
    "    \n",
    "    print('preprosessing the special ticker done!!!...')\n",
    "    print('=======================================================')\n",
    "    \n",
    "    \n",
    "    return M2\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(del_list):\n",
    "    '''\n",
    "    生成财务合并表：merge_file.csv\n",
    "    '''\n",
    "    base_file=preprocess_common(del_list)\n",
    "    file_normal=preprocess_normal(base_file)\n",
    "    file_special=preprocess_special(base_file)\n",
    "    \n",
    "    merge_file=pd.concat([file_normal,file_special])\n",
    "    \n",
    "    common=['PARTY_ID','TICKER_SYMBOL', 'EXCHANGE_CD','PUBLISH_DATE','END_DATE_REP','END_DATE','FISCAL_PERIOD',\\\n",
    "        'REPORT_TYPE', 'MERGED_FLAG', 'category']\n",
    "    \n",
    "    merge_file=merge_file[common+list(set(merge_file.columns)-set(common))]\n",
    "    \n",
    "    \n",
    "    print('the shape of normal ticker file:',file_normal.shape)\n",
    "    print('the shape of special ticker file:',file_special.shape)\n",
    "    print('the shape of merge file:',merge_file.shape)\n",
    "    \n",
    "    merge_file.to_csv(mid_path+'merge_file.csv',index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "    return merge_file\n",
    "    \n",
    "# ##再次check merge_balance,merge_cash，merge_income，M2\n",
    "# ###是否有'TICKER_SYMBOL'-'END_DATE'重复项\n",
    "# '''\n",
    "# 也就是比较drop前后长度是否相等，若相等，则正确\n",
    "# '''\n",
    "# def check_dup(DF):\n",
    "#     print(DF.shape)\n",
    "#     print(DF.drop_duplicates(subset=['TICKER_SYMBOL','END_DATE'], keep='last').shape)\n",
    "\n",
    "# check_dup(M2)\n",
    "T=preprocess(del_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common=['PARTY_ID','TICKER_SYMBOL', 'EXCHANGE_CD','PUBLISH_DATE','END_DATE_REP','END_DATE','FISCAL_PERIOD',\\\n",
    "        'REPORT_TYPE', 'MERGED_FLAG', 'category']\n",
    "\n",
    "\n",
    "T[common+list(set(T.columns)-set(common))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2[M2.TICKER_SYMBOL==30][['TICKER_SYMBOL','END_DATE','REVENUE_commom_income']].sort_values(by=['END_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t=M2.columns.str.contains('REVENUE')\n",
    "#M2.columns[t]\n",
    "submit=pd.read_csv(file_path+'sumbit_v1.csv')\n",
    "base=submit[['TICKER_SYMBOL']]\n",
    "base\n",
    "\n",
    "time_range=['2009-03-31', '2009-06-30', '2009-09-30', '2009-12-31',\n",
    "       '2010-03-31', '2010-06-30', '2010-09-30', '2010-12-31',\n",
    "       '2011-03-31', '2011-06-30', '2011-09-30', '2011-12-31',\n",
    "       '2012-03-31', '2012-06-30', '2012-09-30', '2012-12-31',\n",
    "       '2013-03-31', '2013-06-30', '2013-09-30', '2013-12-31',\n",
    "       '2014-03-31', '2014-06-30', '2014-09-30', '2014-12-31',\n",
    "       '2015-03-31', '2015-06-30', '2015-09-30', '2015-12-31',\n",
    "       '2016-03-31', '2016-06-30', '2016-09-30', '2016-12-31',\n",
    "       '2017-03-31', '2017-06-30', '2017-09-30', '2017-12-31',\n",
    "       '2018-03-31']\n",
    "\n",
    "for month in time_range:\n",
    "    \n",
    "    REVENUE_df=M2[['END_DATE','TICKER_SYMBOL','REVENUE_commom_income']]\n",
    "    t=REVENUE_df[REVENUE_df.END_DATE==month].sort_values(by=['END_DATE']).dropna()\n",
    "    t.rename(columns={'REVENUE_commom_income':month},inplace=True)\n",
    "    base=pd.merge(base,t[['TICKER_SYMBOL',month]],how='left',on=['TICKER_SYMBOL'])\n",
    "    \n",
    "base.to_csv(file_path+'ticker_REVENUE_update.csv',index=False)\n",
    "# q=REVENUE_df[REVENUE_df.TICKER_SYMBOL==1].sort_values(by=['END_DATE']).dropna()\n",
    "# q['END_DATE']=q['END_DATE'].apply(lambda x:datetime.datetime.strftime(x,'%Y-%m-%d'))\n",
    "# q['END_DATE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    ##1.market data 检查value 和申万知否一致\n",
    "    \n",
    "#market_data=pd.read_excel(raw_data_path+'[New] Market Data_20180613.xlsx')\n",
    "#market_data.TICKER_SYMBOL.unique().shape#(3675,)\n",
    "# test_180330=market_data[market_data['END_DATE_']=='2018-03-30'][['TICKER_SYMBOL','MARKET_VALUE']]\n",
    "# check_180830=pd.read_csv(file_path+'Uer_market_2018330.csv')\n",
    "# check_180830=check_180830[['ticker','negMarketValue','marketValue']].rename(columns={'ticker':'TICKER_SYMBOL'})\n",
    "# pd.merge(test_180330,check_180830,how='left',on=['TICKER_SYMBOL']).to_csv(file_path+'check_market_values.csv',index=False)\n",
    "#================================================================\n",
    "    ##2.从三表中读取12表\n",
    "\n",
    "# balance_sheet_Bank,balance_sheet_Securities, balance_sheet_Insurance,balance_sheet_GB,\\\n",
    "# cashFlow_sheet_Bank,cashFlow_sheet_Securities,cashFlow_sheet_Insurance,cashFlow_sheet_GB,\\\n",
    "# income_sheet_Bank,income_sheet_Securities,income_sheet_Insurance,income_sheet_GB=utils.loadingFile(0)\n",
    "\n",
    "#================================================================\n",
    "    ##3.将12个表写到csv中，方便今后读取\n",
    "\n",
    "# file_name=['balance_sheet_Bank','balance_sheet_Securities', 'balance_sheet_Insurance','balance_sheet_GB',\\\n",
    "# 'cashFlow_sheet_Bank','cashFlow_sheet_Securities','cashFlow_sheet_Insurance','cashFlow_sheet_GB',\\\n",
    "# 'income_sheet_Bank','income_sheet_Securities','income_sheet_Insurance','income_sheet_GB']\n",
    "\n",
    "# file_df=[balance_sheet_Bank,balance_sheet_Securities, balance_sheet_Insurance,balance_sheet_GB,\\\n",
    "# cashFlow_sheet_Bank,cashFlow_sheet_Securities,cashFlow_sheet_Insurance,cashFlow_sheet_GB,\\\n",
    "# income_sheet_Bank,income_sheet_Securities,income_sheet_Insurance,income_sheet_GB]\n",
    "\n",
    "# for df,name in zip(file_df,file_name):\n",
    "#     df.to_csv(file_path+'files/financial_data_new/%s.csv'%name)\n",
    "#============================================================================\n",
    "    ## 4.在csv文件中补全00000\n",
    "\n",
    "# A=pd.read_csv(file_path+'sumbit_5_31.csv',encoding='gbk')\n",
    "# A.TICKER_SYMBOL=A.TICKER_SYMBOL.apply(lambda x:'\\t%06d'%x)\n",
    "# A.to_csv(file_path+'523.csv',index=False)\n",
    "\n",
    "# A=pd.read_csv(file_path+'sumbit_5_31.csv',encoding='gbk')\n",
    "# A.TICKER_SYMBOL=A.TICKER_SYMBOL.apply(lambda x:'%06d'%x)\n",
    "# #A.to_csv(file_path+'523.csv',index=False)\n",
    "# for a in A.TICKER_SYMBOL:\n",
    "#     print(a)\n",
    "\n",
    "#==============================================================\n",
    "    ## 5.补全下载数据的ticker\n",
    "# file_df=pd.read_csv(file_path+'cashflow_daily_all.csv')\n",
    "# #file_df=pd.read_hdf(file_path+'CAI.h5',key='data')\n",
    "# ticker_df=pd.read_csv(file_path+'ticker_list_new.csv')\n",
    "# file_tickers=file_df.ticker.unique()\n",
    "# ticker_tickers=ticker_df['0'].values\n",
    "# dfii_list=[x for x in ticker_tickers if x not in file_tickers]\n",
    "# DataFrame(dfii_list).to_csv(file_path+'DIFF-个股资金日流向.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#===================================================================================    \n",
    "    ##三表ticker检查\n",
    "'''\n",
    "compared with 529data:add 5 more tickers\n",
    " array([300747], dtype=int64),\n",
    " array([601066], dtype=int64),\n",
    " array([603650], dtype=int64),\n",
    " array([603666], dtype=int64),\n",
    " array([603693], dtype=int64)]\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Balance=[balance_sheet_Bank_old,balance_sheet_Securities_old,balance_sheet_Insurance_old,balance_sheet_GB_old]\n",
    "# del balance_sheet_Bank_old,balance_sheet_Securities_old,balance_sheet_Insurance_old,balance_sheet_GB_old\n",
    "# Balance\n",
    "\n",
    "# Balance_df=pd.concat(Balance)\n",
    "# Balance_df.TICKER_SYMBOL.unique()#3551\n",
    "\n",
    "# Cash=[cashFlow_sheet_Bank_old,cashFlow_sheet_Securities_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_GB_old]\n",
    "# del cashFlow_sheet_Bank_old,cashFlow_sheet_Securities_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_GB_old\n",
    "# Cash\n",
    "\n",
    "# Cash_df=pd.concat(Cash)\n",
    "# Cash_df.TICKER_SYMBOL.unique()#3551\n",
    "\n",
    "# Income=[income_sheet_Bank_old,income_sheet_Securities_old,income_sheet_Insurance_old,income_sheet_GB_old]\n",
    "# del income_sheet_Bank_old,income_sheet_Securities_old,income_sheet_Insurance_old,income_sheet_GB_old\n",
    "# Income\n",
    "\n",
    "# Income_df=pd.concat(Income)\n",
    "# Income_df.TICKER_SYMBOL.unique()#3551\n",
    "\n",
    "\n",
    "\n",
    "# print('the shape of Balance_df is',Balance_df.TICKER_SYMBOL.unique().shape)#(3556,)\n",
    "# print('the shape of Cash_df is',Cash_df.TICKER_SYMBOL.unique().shape)#(3556,)\n",
    "# print('the shape of Income_df is',Income_df.TICKER_SYMBOL.unique().shape)#()(3556,)\n",
    "\n",
    "\n",
    "# tiker_list=pd.read_csv(file_path+'ticker_list.csv')\n",
    "# tiker_list['0'].unique()\n",
    "\n",
    "\n",
    "# #比较三大表中ticker是否相同\n",
    "# A1=set(Balance_df.TICKER_SYMBOL.unique())\n",
    "# A2=set(Cash_df.TICKER_SYMBOL.unique())\n",
    "# A3=set(Income_df.TICKER_SYMBOL.unique())\n",
    "\n",
    "# print('A1==A2',A1==A2)\n",
    "# print('A1==A3',A1==A3)\n",
    "# print('A2==A3',A2==A3)\n",
    "\n",
    "#DataFrame(sorted(Balance_df.TICKER_SYMBOL.unique())).to_csv(file_path+'ticker_list_new_613.csv',index=False)\n",
    "\n",
    "#===============================================================   \n",
    "    ##检查529和613文件中ticker异同\n",
    "# ticker_529=pd.read_csv(file_path+'ticker_list_new.csv')\n",
    "# ticker_613=pd.read_csv(file_path+'ticker_list_new_613.csv')\n",
    "# [x for x in ticker_613.values if x not in ticker_529.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(Income_df.TICKER_SYMBOL.unique()).to_csv(file_path+'ticker_new.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
