{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ipynb_importer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import utils,preprocess,merge\n",
    "import time\n",
    "import datetime\n",
    "import os,gc\n",
    "file_path='D:/360WiFi/'\n",
    "raw_data_path='D:/360WiFi/FDDC_financial_data_20180613/'\n",
    "split_file_path='D:/360WiFi/files/financial_data_new/'\n",
    "input_path='D:/360WiFi/files/input/'\n",
    "mid_path='D:/360WiFi/files/mid_file/'\n",
    "other_path='D:/360WiFi/files/other_file/'\n",
    "\n",
    "\n",
    "##------------------合表前，初筛列开关--------------------------------------------------------------\n",
    "#资产负债表\n",
    "del_col_Balance_Bank=['AE,AA,LE,LA,SEE,SEA,OTH_EFFECT_SE,OTH_EFFECT_SA,LEE,LEA']\n",
    "del_col_Balance_GB=['CAE,CAA,NCAE,NCAA,AE,AA,CLE,CLA,NCLE,NCLA,LE,LA,SEE,SEA,OTH_EFFECT_SE,OTH_EFFECT_SA,LEE,LEA']\n",
    "del_col_Balance_Insurance=['AE,AA,LE,LA,SEE,SEA,OTH_EFFECT_SE,OTH_EFFECT_SA,LEE,LEA']\n",
    "del_col_Balance_Securities=['AE,AA,LE,LA,SEE,SEA,OTH_EFFECT_SE,OTH_EFFECT_SA,LEE,LEA']\n",
    "\n",
    "#现金流量表\n",
    "del_col_cashFlow_Bank=['SPEC_OCIF,AOCIF,SPEC_OCOF,AOCOF,ANOCF,SPEC_ICIF,AICIF,SPEC_ICOF,AICOF,ANICF,SPEC_FCIF,AFCIF,SPEC_FCOF,AFCOF,ANFCF,OTH_EFFECT_CE,ACE,OTH_EFFECT_CEI,ACEI']\n",
    "del_col_cashFlow_GB=['SPEC_OCIF,AOCIF,SPEC_OCOF,AOCOF,ANOCF,SPEC_ICIF,AICIF,SPEC_ICOF,AICOF,ANICF,SPEC_FCIF,AFCIF,SPEC_FCOF,AFCOF,ANFCF,OTH_EFFECT_CE,ACE,OTH_EFFECT_CEI,ACEI']\n",
    "del_col_cashFlow_Insurance=['SPEC_OCIF,AOCIF,SPEC_OCOF,AOCOF,ANOCF,SPEC_ICIF,AICIF,SPEC_ICOF,AICOF,ANICF,SPEC_FCIF,AFCIF,SPEC_FCOF,AFCOF,ANFCF,OTH_EFFECT_CE,ACE,OTH_EFFECT_CEI,ACEI']\n",
    "del_col_cashFlow_Securities=['SPEC_OCIF,AOCIF,SPEC_OCOF,AOCOF,ANOCF,SPEC_ICIF,AICIF,SPEC_ICOF,AICOF,ANICF,SPEC_FCIF,AFCIF,SPEC_FCOF,AFCOF,ANFCF,OTH_EFFECT_CE,ACE,OTH_EFFECT_CEI,ACEI']\n",
    "\n",
    "\n",
    "#利润表\n",
    "del_col_Income_Bank=['SPEC_OR,AOR,SPEC_OC,AOC,OTH_EFFECT_OP,AE_EFFECT_OP,OTH_EFFECT_TP,AE_EFFECT_TP,OTH_EFFECT_NP,AE_EFFECT_NP,OTH_EFFECT_NPP,AE_EFFECT_NPP,OTH_EFFECT_CI,AE_EFFECT_CI,OTH_EFFECT_PCI,AE_EFFECT_PCI']\n",
    "del_col_Income_GB=['SPEC_TOR,ATOR,SPEC_TOC,ATOC,OTH_EFFECT_OP,AE_EFFECT_OP,OTH_EFFECT_TP,AE_EFFECT_TP,OTH_EFFECT_NP,AE_EFFECT_NP,OTH_EFFECT_NPP,AE_EFFECT_NPP,OTH_EFFECT_CI,AE_EFFECT_CI,OTH_EFFECT_PCI,AE_EFFECT_PCI']\n",
    "del_col_Income_Insurance=['SPEC_OR,AOR,SPEC_OC,AOC,OTH_EFFECT_OP,AE_EFFECT_OP,OTH_EFFECT_TP,AE_EFFECT_TP,OTH_EFFECT_NP,AE_EFFECT_NP,OTH_EFFECT_NPP,AE_EFFECT_NPP,OTH_EFFECT_CI,AE_EFFECT_CI,OTH_EFFECT_PCI,AE_EFFECT_PCI']\n",
    "del_col_Income_Securities=['SPEC_OR,AOR,SPEC_OC,AOC,OTH_EFFECT_OP,AE_EFFECT_OP,OTH_EFFECT_TP,AE_EFFECT_TP,OTH_EFFECT_NP,AE_EFFECT_NP,OTH_EFFECT_NPP,AE_EFFECT_NPP,OTH_EFFECT_CI,AE_EFFECT_CI,OTH_EFFECT_PCI,AE_EFFECT_PCI']\n",
    "\n",
    "\n",
    "\n",
    "del_list=[del_col_Balance_Bank,del_col_Balance_GB,del_col_Balance_Insurance,del_col_Balance_Securities,\\\n",
    "         del_col_cashFlow_Bank,del_col_cashFlow_GB,del_col_cashFlow_Insurance,del_col_cashFlow_Securities,\\\n",
    "        del_col_Income_Bank,del_col_Income_GB,del_col_Income_Insurance,del_col_Income_Securities]\n",
    "\n",
    "\n",
    "##------------------合表后，删列/删行开关-------------------------------------\n",
    "\n",
    "class_option='classifi_by_14L1'\n",
    "\n",
    "\n",
    "##'END_DATE'会在函数中删除，'REVENUE_commom_income'作为特征,暂不删除\n",
    "\n",
    "del_col=['PARTY_ID','EXCHANGE_CD', 'PUBLISH_DATE','END_DATE_REP',\\\n",
    "          'REPORT_TYPE','MERGED_FLAG', 'category',\\\n",
    "        'industryName_level_1','industryName_level_2','industryName_level_3','isNew','Mid_L2','Mid_L3',\\\n",
    "         'industryID_level_1','industryID_level_2','industryID_level_3',\\\n",
    "         'PUBLISH_DATE_y','PUBLISH_DATE_x','END_DATE_REP_x','END_DATE_REP_y'\n",
    "        ]\n",
    "\n",
    "\n",
    "'''\n",
    "ticker_option的value中：第一项是起始时间，第二项是结束时间，第三项是要删的表，有四种选项['income','balance','cash','all']\n",
    "\n",
    "'''\n",
    "ticker_option={'601360':['2009-03-31','2018-03-31','all'],\n",
    "               '600048':['2017-12-31','2018-03-31','all'],\n",
    "               '600409':['2017-12-31','2018-03-31','all'],\n",
    "               '600693':['2017-12-31','2018-03-31','all'],\n",
    "               '600939':['2017-12-31','2018-03-31','all'],\n",
    "               '600399':['2017-12-31','2018-03-31','all'],\n",
    "               '600610':['2017-12-31','2018-03-31','all'],\n",
    "               '600094':['2009-03-31','2009-09-30','all'],\n",
    "              }\n",
    "\n",
    "##--------------one_hot开关------------------------------------\n",
    "\n",
    "oht_col=['TICKER_SYMBOL','FISCAL_PERIOD','industrySymbol_level_1','industrySymbol_level_2','industrySymbol_level_1',\\\n",
    "        'indexSymbol_level_1','indexSymbol_level_2','indexSymbol_level_3',\\\n",
    "        ]\n",
    "# merge.preprocess(del_list)\n",
    "# merge.generate_data_base()\n",
    "# merge.merge_3file()\n",
    "# preprocess.select_table(tabel,class_option,del_col,ticker_option)\n",
    "# preprocess.make_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table=pd.read_csv(mid_path+'feature_importance_2.csv')\n",
    "# table.get_dtype_counts()\n",
    "# t=table.infer_objects().dtypes\n",
    "# t[t=='int64']\n",
    "\n",
    "# table['date']=table['year'].astype(str)+table['month'].apply(lambda x:\"%02d\"%x)\n",
    "# table[['date','year','month']]\n",
    "\n",
    "# T=pd.get_dummies(table,columns=['FISCAL_PERIOD'])\n",
    "# T.get_dtype_counts()\n",
    "# header=['date','FISCAL_PERIOD_3', 'FISCAL_PERIOD_6', 'FISCAL_PERIOD_9', 'FISCAL_PERIOD_12']\n",
    "# T=T[header+list((set(T.columns)-set(header)))]\n",
    "# T\n",
    "# T.get_dtype_counts()\n",
    "\n",
    "# dangji=pd.read_csv(mid_path+'table_6_file_label.csv')\n",
    "# dangji.rename(columns={'label':'Revenue_now'},inplace=True)\n",
    "\n",
    "# merge=pd.merge(T,dangji[['TICKER_SYMBOL','year','month','Revenue_now']],how='left',on=['TICKER_SYMBOL','year','month'])\n",
    "# rr=merge[['TICKER_SYMBOL','year','month','Revenue_now','label']]\n",
    "# rr[rr.year!=2018].to_csv(other_path+'check_revenue_prerevenue.csv',index=False)\n",
    "\n",
    "#merge.drop(['year','month','TICKER_SYMBOL','REVENUE_commom_income'],axis=1,inplace=True)\n",
    "# table\n",
    "#merge.get_dtype_counts()\n",
    "#merge[merge.date!='201803'].to_csv(other_path+'feature_importance_2_update.csv',index=False)\n",
    "preprocess.make_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_data():\n",
    "    '''\n",
    "    生成初步跑的大表（按要求筛掉部分宏观信息和company_operation 信息）,feature_importance.csv\n",
    "    \n",
    "    '''\n",
    "    table=pd.read_csv(mid_path+'table_6_file_label_new.csv')\n",
    "    table=preprocess.select_table(table,class_option,del_col,ticker_option)\n",
    "\n",
    "    table.drop(table.columns[355:427],axis=1,inplace=True)\n",
    "    table.drop(['industrySymbol_level_1','industrySymbol_level_2','industrySymbol_level_3',\\\n",
    "                'indexSymbol_level_1','indexSymbol_level_2','indexSymbol_level_3','classifi_by_14L1',],axis=1,inplace=True)\n",
    "    table.to_csv(other_path+'feature_importance.csv',index=False)\n",
    "    print('the feature_importance.csv  shape:',table.shape)\n",
    "    return \n",
    "\n",
    "check_revenue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##探究主表的列类型\n",
    "\n",
    "\n",
    "#A.columns[A.columns.str.contains('REVE')]#列中包含某字符的列名\n",
    "#A.get_dtype_counts() 列的类型计数\n",
    "\n",
    "#A.infer_objects().dtypes#具体到每列的类型\n",
    "#t#[t=='object']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare(df1,df2):\n",
    "#     '''\n",
    "#     比较表间ticker异同\n",
    "    \n",
    "#     '''\n",
    "#     print(len(df1.TICKER_SYMBOL.unique()))\n",
    "#     print(len(df2.TICKER_SYMBOL.unique()))\n",
    "#     print(set(df1.TICKER_SYMBOL.unique())-set(df2.TICKER_SYMBOL.unique()))\n",
    "#     print(set(df2.TICKER_SYMBOL.unique())-set(df1.TICKER_SYMBOL.unique()))\n",
    "    \n",
    "    \n",
    "# compare(balance_sheet_Securities_old,income_sheet_Securities_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    ##1.market data 检查value 和申万知否一致\n",
    "    \n",
    "#market_data=pd.read_excel(raw_data_path+'[New] Market Data_20180613.xlsx')\n",
    "#market_data.TICKER_SYMBOL.unique().shape#(3675,)\n",
    "# test_180330=market_data[market_data['END_DATE_']=='2018-03-30'][['TICKER_SYMBOL','MARKET_VALUE']]\n",
    "# check_180830=pd.read_csv(file_path+'Uer_market_2018330.csv')\n",
    "# check_180830=check_180830[['ticker','negMarketValue','marketValue']].rename(columns={'ticker':'TICKER_SYMBOL'})\n",
    "# pd.merge(test_180330,check_180830,how='left',on=['TICKER_SYMBOL']).to_csv(file_path+'check_market_values.csv',index=False)\n",
    "#================================================================\n",
    "    ##2.从三表中读取12表\n",
    "\n",
    "# balance_sheet_Bank,balance_sheet_Securities, balance_sheet_Insurance,balance_sheet_GB,\\\n",
    "# cashFlow_sheet_Bank,cashFlow_sheet_Securities,cashFlow_sheet_Insurance,cashFlow_sheet_GB,\\\n",
    "# income_sheet_Bank,income_sheet_Securities,income_sheet_Insurance,income_sheet_GB=utils.loadingFile(0)\n",
    "\n",
    "#================================================================\n",
    "    ##3.将12个表写到csv中，方便今后读取\n",
    "\n",
    "# file_name=['balance_sheet_Bank','balance_sheet_Securities', 'balance_sheet_Insurance','balance_sheet_GB',\\\n",
    "# 'cashFlow_sheet_Bank','cashFlow_sheet_Securities','cashFlow_sheet_Insurance','cashFlow_sheet_GB',\\\n",
    "# 'income_sheet_Bank','income_sheet_Securities','income_sheet_Insurance','income_sheet_GB']\n",
    "\n",
    "# file_df=[balance_sheet_Bank,balance_sheet_Securities, balance_sheet_Insurance,balance_sheet_GB,\\\n",
    "# cashFlow_sheet_Bank,cashFlow_sheet_Securities,cashFlow_sheet_Insurance,cashFlow_sheet_GB,\\\n",
    "# income_sheet_Bank,income_sheet_Securities,income_sheet_Insurance,income_sheet_GB]\n",
    "\n",
    "# for df,name in zip(file_df,file_name):\n",
    "#     df.to_csv(file_path+'files/financial_data_new/%s.csv'%name)\n",
    "#============================================================================\n",
    "    ## 4.在csv文件中补全00000\n",
    "\n",
    "# A=pd.read_csv(file_path+'sumbit_5_31.csv',encoding='gbk')\n",
    "# A.TICKER_SYMBOL=A.TICKER_SYMBOL.apply(lambda x:'\\t%06d'%x)\n",
    "# A.to_csv(file_path+'523.csv',index=False)\n",
    "\n",
    "# A=pd.read_csv(file_path+'sumbit_5_31.csv',encoding='gbk')\n",
    "# A.TICKER_SYMBOL=A.TICKER_SYMBOL.apply(lambda x:'%06d'%x)\n",
    "# #A.to_csv(file_path+'523.csv',index=False)\n",
    "# for a in A.TICKER_SYMBOL:\n",
    "#     print(a)\n",
    "\n",
    "#==============================================================\n",
    "    ## 5.补全下载数据的ticker\n",
    "# file_df=pd.read_csv(file_path+'cashflow_daily_all.csv')\n",
    "# #file_df=pd.read_hdf(file_path+'CAI.h5',key='data')\n",
    "# ticker_df=pd.read_csv(file_path+'ticker_list_new.csv')\n",
    "# file_tickers=file_df.ticker.unique()\n",
    "# ticker_tickers=ticker_df['0'].values\n",
    "# dfii_list=[x for x in ticker_tickers if x not in file_tickers]\n",
    "# DataFrame(dfii_list).to_csv(file_path+'DIFF-个股资金日流向.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#===================================================================================    \n",
    "    ##三表ticker检查\n",
    "'''\n",
    "compared with 529data:add 5 more tickers\n",
    " array([300747], dtype=int64),\n",
    " array([601066], dtype=int64),\n",
    " array([603650], dtype=int64),\n",
    " array([603666], dtype=int64),\n",
    " array([603693], dtype=int64)]\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Balance=[balance_sheet_Bank_old,balance_sheet_Securities_old,balance_sheet_Insurance_old,balance_sheet_GB_old]\n",
    "# del balance_sheet_Bank_old,balance_sheet_Securities_old,balance_sheet_Insurance_old,balance_sheet_GB_old\n",
    "# Balance\n",
    "\n",
    "# Balance_df=pd.concat(Balance)\n",
    "# Balance_df.TICKER_SYMBOL.unique()#3551\n",
    "\n",
    "# Cash=[cashFlow_sheet_Bank_old,cashFlow_sheet_Securities_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_GB_old]\n",
    "# del cashFlow_sheet_Bank_old,cashFlow_sheet_Securities_old,cashFlow_sheet_Insurance_old,cashFlow_sheet_GB_old\n",
    "# Cash\n",
    "\n",
    "# Cash_df=pd.concat(Cash)\n",
    "# Cash_df.TICKER_SYMBOL.unique()#3551\n",
    "\n",
    "# Income=[income_sheet_Bank_old,income_sheet_Securities_old,income_sheet_Insurance_old,income_sheet_GB_old]\n",
    "# del income_sheet_Bank_old,income_sheet_Securities_old,income_sheet_Insurance_old,income_sheet_GB_old\n",
    "# Income\n",
    "\n",
    "# Income_df=pd.concat(Income)\n",
    "# Income_df.TICKER_SYMBOL.unique()#3551\n",
    "\n",
    "\n",
    "\n",
    "# print('the shape of Balance_df is',Balance_df.TICKER_SYMBOL.unique().shape)#(3556,)\n",
    "# print('the shape of Cash_df is',Cash_df.TICKER_SYMBOL.unique().shape)#(3556,)\n",
    "# print('the shape of Income_df is',Income_df.TICKER_SYMBOL.unique().shape)#()(3556,)\n",
    "\n",
    "\n",
    "# tiker_list=pd.read_csv(file_path+'ticker_list.csv')\n",
    "# tiker_list['0'].unique()\n",
    "\n",
    "\n",
    "# #比较三大表中ticker是否相同\n",
    "# A1=set(Balance_df.TICKER_SYMBOL.unique())\n",
    "# A2=set(Cash_df.TICKER_SYMBOL.unique())\n",
    "# A3=set(Income_df.TICKER_SYMBOL.unique())\n",
    "\n",
    "# print('A1==A2',A1==A2)\n",
    "# print('A1==A3',A1==A3)\n",
    "# print('A2==A3',A2==A3)\n",
    "\n",
    "#DataFrame(sorted(Balance_df.TICKER_SYMBOL.unique())).to_csv(file_path+'ticker_list_new_613.csv',index=False)\n",
    "\n",
    "#===============================================================   \n",
    "    ##检查529和613文件中ticker异同\n",
    "# ticker_529=pd.read_csv(file_path+'ticker_list_new.csv')\n",
    "# ticker_613=pd.read_csv(file_path+'ticker_list_new_613.csv')\n",
    "# [x for x in ticker_613.values if x not in ticker_529.values]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
